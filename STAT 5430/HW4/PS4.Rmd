---
title: "HW4"
output: pdf_document
author: "Sam Olson"
---

# Problem 1

**Problem 6.2, Casella and Berger (2nd Edition)**

**6.2** Let $X_1, \dots, X_n$ be independent random variables with densities  

$$
f_{X_i}(x | \theta) =
\begin{cases} 
e^{\theta - x} & x \geq i\theta \\
0 & x < i\theta.
\end{cases}
$$

Prove that $T = \min_i (X_i / i)$ is a sufficient statistic for $\theta$.  

\newpage 

# Problem 2

**Example of Rao-Blackwell theorem, which is largely a STAT 5420 problem in computation.**

Let $X_1$ and $X_2$ be iid Bernoulli$(p)$, $0 < p < 1$.

## a) 

Show $S = X_1 + X_2$ is sufficient for $p$.

## b) 

Identify the conditional probability $P(X_1 = x | S = s)$; you should know which values of $x, s$ to consider.

## c) 

Find the conditional expectation $T \equiv E(X_1 | S)$, i.e., as a function of the possibilities of $S$. Note that $T$ is a statistic.

## d) 

Show $X_1$ and $T$ are both unbiased for $p$.

## e) 

Show $\text{Var}_p(T) \leq \text{Var}_p(X_1)$, for any $p$.

\newpage

# Problem 3

**Problem 6.21 a)-b), Casella and Berger (2nd Edition)**

**6.21** Let $X$ be one observation from the pdf  

$$
f(x | \theta) = \left(\frac{\theta}{2}\right)^{|x|} (1 - \theta)^{1 - |x|}, \quad x = -1, 0, 1, \quad 0 \leq \theta \leq 1.
$$

## a) 

Is $X$ a complete sufficient statistic?  

## b) 

Is $|X|$ a complete sufficient statistic?  

\newpage 

# Problem 4

**Problem 6.24, Casella and Berger (2nd Edition)**

**6.24** Consider the following family of distributions:  

$$
\mathcal{P} = \{ P_{\lambda}(X = x) : P_{\lambda}(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}; x = 0,1,2,\dots ; \lambda = 0 \text{ or } 1 \}.
$$

This is a Poisson family with $\lambda$ restricted to be $0$ or $1$. Show that the family $\mathcal{P}$ is *not complete*, demonstrating that completeness can be dependent on the range of the parameter. (See Exercises 6.15 and 6.18.)  

\newpage 

# Problem 5

**Problem 7.57, Casella and Berger (2nd Edition)** You may assume $n \geq 3$.

One has to Rao-Blackwellize on the complete/sufficient statistic here

$$\sum_{i=1}^{n+1} X_i.$$

**7.57** Let $X_1, \dots, X_{n+1}$ be iid Bernoulli$(p)$, and define the function $h(p)$ by  

$$
h(p) = P \left( \sum_{i=1}^{n} X_i > X_{n+1} \middle| p \right),
$$

the probability that the first $n$ observations exceed the $(n+1)$st.  

## a) 

Show that  

$$
T(X_1, \dots, X_{n+1}) =  
\begin{cases} 
1 & \text{if } \sum_{i=1}^{n} X_i > X_{n+1} \\
0 & \text{otherwise}
\end{cases}
$$

is an unbiased estimator of $h(p)$.  

## b) 

Find the best unbiased estimator of $h(p)$.  
