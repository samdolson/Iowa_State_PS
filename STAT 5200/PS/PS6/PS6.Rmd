---
title: "Statistics 520 - Assignment 6"
author: "Sam Olson"
output: pdf_document
---

## The Model

Define random variables $Y_1, \dots, Y_n$ connected with the growth of some organism, observed at times $t_1, \dots, t_n$. Assume the response variables are independent and follow the model:

$$
Y_i = \mu_i + \sigma \varepsilon_i,
$$

$$
\mu_i = B + A \exp\!\Big[ - \exp\{ -k(t_i - T) \} \Big],
$$

$$
\varepsilon_i \overset{\text{iid}}{\sim} N(0, 1).
$$

This model describes a sigmoidal curve with both upper and lower asymptotes, but is not constrained to be symmetric about its inflection point in the way a logistic curve is.

### Parameters

- A: distance between upper and lower asymptotes  
- B: lower asymptote  
- k: growth rate (slope of the linear portion of the curve)  
- T: the time at which the inflection point occurs  

### Data

On the course web page in the Data module is a file `growthdat.txt` that contains data simulated from the Gompertz regression model. The variable names in this file are `x` and `y`, where:

- `x` = time of observation  
- `y` = growth in appropriate units  

\newpage 

```{r, echo = F, warning = F, message = F}
source("C:/Users/samue/OneDrive/Desktop/Iowa_State_PS/STAT 5200/PS/PS6/nonlin.txt")
library(kableExtra)
library(knitr)
dat <- read.table("C:/Users/samue/OneDrive/Desktop/Iowa_State_PS/STAT 5200/PS/PS6/growthdat.txt", header = TRUE)
```

## Q1

Find generalized least squares estimates of the parameters $A, B, k, T$, and the associated moment-based estimate of $\sigma^2$. Describe how you determined effective starting values for the estimation procedure. Present a scatterplot along with the fitted expectation function.  

### Answer 

As given, the form of four-parameter Gompertz model is: 

$$
\mu_i = B + A \exp\!\Big[ - \exp\{ -k(t_i - T) \} \Big]
$$

Again, as given, the parameters are:

* (A): distance between the upper and lower asymptotes,
* (B): lower asymptote,
* (k): growth rate (slope at the inflection point),
* (T): time of inflection,

To determine "effective" starting values, we check the underlying data visually and descriptively, i.e., we intuited the values inductively. Also, since there is no reasonable basis to suppose numbers must be discrete, the observed values were largely used as starting values (treated observations as realizations of continuous R.V.s).

The values used (and how they were determined) are as follows: 

* Lower asymptote (B): The min observed y-value is 0.948, so set ($B \approx 0.95$).

* Distance between the upper and lower asymptotes (A): The max observed y-value is 233.37. So, to get A we take the (observed) range ($A \approx 232.42$).

* Time of Inflection (T): From visual inspection, the curve rises steeply from t = 10 to t = 20; taking the midpoint of this period as an initial starting point for "inflection" ($T \approx 15$), knowing that the optimization method, particularly a Newton-type optimizer, will more accurately determine the "direction" to proceed for maximization.

* Growth rate (k): A more involved calculation The steepest rise in the data occurs between t=12 and t=18. Case in point, between t=13 ($y \approx 64$) and t=17 ($y \approx 140$), the increase is about 76 units over 4 time units, or roughly 19 units per time unit.

For the Gompertz model, the slope at the inflection point ($t=T$) is obtained by differentiation:

$$
\left.\frac{d\mu}{dt}\right|_{t=T} = \frac{Ak}{e}
$$

(Where "e" denotes Euler's number, not Euler's constant)

Equating this theoretical slope with the observed slope ($\approx 19$) and using $A \approx 232$ from prior determination, we obtain the starting value

$$
k \approx \frac{19e}{232} \approx 0.22
$$

Taken together, the starting parameter vector is

$$
\theta^{(0)} = (A=232.42, B=0.95, k=0.22, T=15)
$$


Actual Computation yields: 

```{r, echo = F, warning = F, message = F, results = F}
# expectation 
gompertz_fun <- function(x, p) {
  A <- p[1]; B <- p[2]; k <- p[3]; T <- p[4]
  B + A * exp(-exp(-k*(x - T)))
}

# derivative matrix
gompertz_der <- function(x, p) {
  A <- p[1]; B <- p[2]; k <- p[3]; T <- p[4]
  z <- -k*(x - T)
  e1 <- exp(z)
  e2 <- exp(-e1)
  dA <- e2
  dB <- rep(1, length(x))
  dk <- A * (x - T) * e1 * e2
  dT <- -A * k * e1 * e2
  cbind(dA, dB, dk, dT)
}

# variance weights, use inverse variance weighting 
wts <- function(x, p) diag(rep(1, length(x)))

## Fit with nonlin()
start <- c(232.42, 0.95, 0.22, 15)
out <- nonlin(dat$x, dat$y, start, gompertz_fun, gompertz_der, wts)

# parameter estimates
# out$bs
# moment-based estimate of sigma^2
# out$sshat   
```

Convergence met with estimates: 

$\hat A = 201.30$
$\hat B = 9.76$
$\hat k = 0.35$
$\hat T = 14.26$
$\hat \sigma^2 = 85.57$

Plotting the observed vs. estimated values: 

```{r, echo = F, warning = F, message = F}
plot(dat$x, dat$y, pch=19, main="Gompertz Growth Fit",
     xlab="Time", ylab="Growth")
lines(dat$x, out$yhat, col="blue", lwd=2)
```

\newpage 

## Q2 

Compute 95% approximate confidence intervals for the parameters of the expectation function ($A, B, k, T$).  

### Answer

The `nonlin` function returns the parameter estimates ($\hat{\boldsymbol\beta}=(\hat A,\hat B,\hat k,\hat T)$) and an estimated covariance matrix ($\widehat{\mathrm{Var}}(\hat{\boldsymbol\beta})=\mathbf V$)

Then, following the standard convention, the formula for the 95% (Wald-based approximate) confidence intervals for each parameter ($\beta_j\in{A,B,k,T}$) are: 

$$
\hat\beta_j \ \pm\ z_{0.975},\mathrm{SE}(\hat\beta_j)
$$

```{r, echo = F, warning = F, message = F}
# asymptotic Wald-type
ests <- out$bs
V    <- out$covb
se   <- sqrt(diag(V))
z    <- qnorm(0.975)

ci_L <- ests - z*se
ci_U <- ests + z*se

ci_tbl <- data.frame(
  param = c("A","B","k","T"),
  estimate = ests,
  SE = se,
  CI_L = ci_L,
  CI_U = ci_U,
  row.names = NULL
)

ci_tbl[] <- lapply(ci_tbl, function(x) if(is.numeric(x)) round(x, 3) else x)
kable(ci_tbl)
```

Corresponding to 95% approximate confidence intervals of: 

* (A: $201.296 \pm 1.96(4.974)\ \Rightarrow\ (191.546,\ 211.045)$)
* (B: $9.763 \pm 1.96(2.809)\ \Rightarrow\ \ \ (4.258,\ \ 15.268)$)
* (k: $0.354 \pm 1.96(0.032)\ \Rightarrow\ \ (0.290,\ \ \ 0.417)$)
* (T: $14.257 \pm 1.96(0.195)\ \Rightarrow\ (13.875,\ 14.639)$)

```{r, echo = F, warning = F, message = F}
# delta method
# also asymptotic, Wald-type, but on transformed data (log) 

log_ci <- function(theta_hat, var_hat, level = 0.95) {
  z <- qnorm(0.5 + level/2)
  m <- log(theta_hat)
  se_log <- sqrt(var_hat) / theta_hat
  exp(c(m - z*se_log, m + z*se_log))
}

# A_log_CI <- log_ci(ests[1], V[1,1])
# B_log_CI <- log_ci(ests[2], V[2,2])
# k_log_CI <- log_ci(ests[3], V[3,3])
# T_log_CI <- log_ci(ests[4], V[4,4])
# 
# print("A CI")
# A_log_CI
# print("B CI")
# B_log_CI
# print("k CI")
# k_log_CI
# print("T CI")
# T_log_CI
```

\newpage 

## Q3 

Compute pairwise correlations between $\hat{A}, \hat{B}, \hat{k}, \hat{T}$.  

### Answer

The `nonlin()` output includes the estimated covariance matrix of the parameter estimates (`out$covb`). From this matrix we can derive the correlations:

$$
\text{Corr}(\hat\theta_i, \hat\theta_j) =
\frac{\widehat{\text{Cov}}(\hat\theta_i,\hat\theta_j)}
{\sqrt{\widehat{\text{Var}}(\hat\theta_i)};\sqrt{\widehat{\text{Var}}(\hat\theta_j)}}
$$

for parameters ($\theta_i, \theta_j \in \{A,B,k,T\}$).

Computing these quantities, using the `cov2cor` function from the base `stats` package: 

```{r, echo = F, warning = F, message = F}
# start with covariance matrix
V <- out$covb

# cov2cor from stats, nifty! 
cor_mat <- cov2cor(V)

# label
colnames(cor_mat) <- rownames(cor_mat) <- c("A","B","k","T")

kable(round(cor_mat,3))
```

\newpage 

## Q4

Two quantities of interest to scientists are called the maximum relative growth rate and the maximum absolute growth rate. These quantities are related to the slope of the growth curve at the inflection point and give the per time unit increase in growth relative to the upper asymptote and in absolute scale at that time point. The maximum absolute growth rate is defined as, 

$$
k_{\text{abs}} = \frac{k(A + B)}{\exp(1)}
$$

A plug-in estimate of $k_{abs}$ is then

$$
\hat{k}_{\text{abs}} = \frac{\hat{k}(\hat{A} + \hat{B})}{\exp(1)}
$$

and note that $k_{abs}$ is an absolute function of its components. Given this, compute a 90% approximate confidence interval for $k_{abs}$ (note a 90% interval -- I get tired of using 95% all the time). Outline the procedure you used to calculate the quantities needed.

### Answer

As defined,

$$
k_{\text{abs}} \;=\; \frac{k(A+B)}{e}
$$

Given $(\hat A,\hat B,\hat k,\hat T)$ from Q1 and the estimated covariance matrix from Q3, we can (again, like Q2) use a Wald (delta-method) interval.

Let $g(A,B,k,T) = k(A+B)/e$. Its gradient at $\hat\theta$ is

$$
\nabla g(\hat\theta)
= \left(\frac{\partial g}{\partial A},\frac{\partial g}{\partial B},\frac{\partial g}{\partial k},\frac{\partial g}{\partial T}\right)^\top
= \left(\frac{\hat k}{e},\ \frac{\hat k}{e},\ \frac{\hat A+\hat B}{e},\ 0\right)^\top
$$

Then

$$
\widehat{\operatorname{Var}}(\hat k_{\text{abs}})
= \nabla g(\hat\theta)^\top\ \widehat{\operatorname{Cov}}(\hat\theta)\ \nabla g(\hat\theta)
$$

And 

$$
\operatorname{SE}(\hat k_{\text{abs}}) = \sqrt{\widehat{\operatorname{Var}}(\hat k_{\text{abs}})}
$$

For a (presumably two-sided) 90\% CI, using $z_{0.95}=1.645$:

$$
\hat k_{\text{abs}} \ \pm\ 1.645 \cdot \operatorname{SE}(\hat k_{\text{abs}})
$$

Computing:

```{r, echo = F, warning = F, message = F}
# order: A, B, k, T
Ahat <- out$bs[1]
Bhat <- out$bs[2]
khat <- out$bs[3]  
V    <- out$covb

k_abs_hat <- khat * (Ahat + Bhat) / exp(1)

# d/d(A,B,k,T)
grad <- c(khat/exp(1), khat/exp(1), (Ahat + Bhat)/exp(1), 0)  
var_kabs <- as.numeric(t(grad) %*% V %*% grad)
se_kabs  <- sqrt(var_kabs)

# 1.645 for 90% two-sided
# alpha / 2 = 0.05, hence 95 here 
z <- qnorm(0.95)  
ci90 <- c(k_abs_hat - z*se_kabs, k_abs_hat + z*se_kabs)

# k_abs_hat
# ci90
sprintf(
  "A 90%% approximate confidence interval for k_abs is (%.3f, %.3f)",
  ci90[1], ci90[2]
)
```
