---
title: "HW3"
output: pdf_document
author: "Samuel Olson" 
---

```{r, eval = T, results = F, echo = F, warning = F, message = F}
library(knitr)
```

```{r, eval = F, echo=FALSE, fig.cap="CocoMelon", out.width = '100%'}
knitr::include_graphics("Algorithm.png")
```

# Outline 

  - Q1: part f) through i) need re-review
  - Q2: part f) and i)
  - Q2: part j), k), l)

# Problem 1

Case Study 5.1.1 from *The Statistical Sleuth* describes a dietary restriction study. Female mice were assigned to one of the following six treatment groups:

1. **NP:** unlimited, nonpurified, standard feed
2. **N/N85:** normal diet before weaning and normal diet (85 kcal/week) after weaning
3. **N/R50:** normal diet before weaning and reduced calorie (50 kcal/week) after weaning
4. **R/R50:** reduced calorie diet before and after weaning (50 kcal/week)
5. **N/R50lopro:** normal diet before weaning, reduced calorie (50 kcal/week) after weaning, and reduced protein
6. **N/R40:** normal diet before weaning and severely reduced calorie (40 kcal/week) after weaning

The response of interest was mouse lifetime in months.

Download the corresponding data file at [http://www.statisticalsleuth.com/](http://www.statisticalsleuth.com/) or access it by installing and loading the R package `Sleuth3` and examining `case0501`. To do that latter, try the following R commands:

```{r}
require(Sleuth3)
# case0501
```

Complete the following parts under the assumption that a Gauss-Markov model with normal errors and an unrestricted mean for each of the six treatment groups is appropriate for these data.

## Note: 

Doing this problem primarily in R. 

## a)

Create side-by-side boxplots of the response for this dataset, with one boxplot for each treatment group. Be sure to clearly label the axes of your plot.

```{r}
boxplot(formula = Lifetime ~ Diet,
        data = case0501, 
        main = "Response By Treatment Group - BoxPlots",
        xlab="Treatment Group", 
        ylab = "Life Expectancy (Months)")
```

\newpage 

## b)

Find the SSE (sum of squared errors) for the full model with one unrestricted mean for each of the six treatment groups.

```{r}
lm(formula = Lifetime ~ Diet,
          data = case0501) |> 
  deviance()
```

\newpage 

## c)

Compute $\hat{\sigma}^2$ for the full model.

```{r}
fullModel <- lm(formula = Lifetime ~ Diet,
          data = case0501)

numer <- lm(formula = Lifetime ~ Diet,
          data = case0501) |> 
          deviance()
denom <- fullModel$df

# denom

numer/denom
```

\newpage 

## d)

Find the SSE for a reduced model that has one common mean for the N/N85, N/R50, N/R50lopro, and N/R40 treatment groups and unrestricted means for the other two treatment groups.

```{r}
require(dplyr)
# Modify 
# levels(case0501$Diet)
# "N/N85" "N/R40" "N/R50" "NP"    "R/R50" "lopro"
mergedGroup <- levels(case0501$Diet)[c(1,3,6,2)]

reduced <- case0501 |>
  mutate(
    newDiet = case_when(
      Diet %in% mergedGroup ~ "N/N85+N/R50+N/R50lopro+N/R40",
      # only change mergedGroup matches
      TRUE ~ as.character(Diet) 
    )
  ) |>
  mutate(newDiet = factor(newDiet))

redModel <- lm(Lifetime ~ newDiet, 
           data = reduced)
deviance(redModel)
```

\newpage 

## e)

Use the answers from parts b) through d) to compute an F-statistic for testing the null hypothesis that the mean of the response vector is in the column space associated with the reduced model vs. the alternative that the mean of the response vector is in the column space of the full model but not in the column space of the reduced model.

Explicitly, we're testing: 

$$
H_0: E(\boldsymbol{y}) \in \mathcal{C}(\boldsymbol{\mathbf{X}}_0)
$$

$$
H_a: E(\boldsymbol{y}) \in \mathcal{C}(\mathbf{X}) \setminus \mathcal{C}(\mathbf{X}_0)
$$

Using the answers from the prior parts of the question, noting the difference in degrees of freedom between the full and reduced model is 3 (Combining 4 groups into 1 group effectively frees up 3 extra degrees of freedom): 

$$
F = \frac{(SSE_{\text{Reduced}} - SSE_{\text{Full}}) / (df_{\text{Reduced}} - df_{\text{Full}})}{SSE_{\text{Full}} / df_{\text{Full}}} = \frac{\left((20287.99 - 15297.42) / 3 \right)}{(15297.42/343)} = 37.3
$$

Checking directly against the R output comparing the two models: 

```{r}
anova(redModel, fullModel)
```

\newpage 

## f)

Explain to the scientists conducting this study what the F-statistic in part e) can be used to test. Consider the context of the study (i.e., pay attention to the description of the experiment and the descriptions of the treatments) and use terms non-statistician scientists will understand.

The partial F-test, comparing the full and reduced model, in part e) is evidence to to test whether the full model is significantly better than the reduced model. This is to say we're testing whether we should/whether it is appropriate to group together the N/N85, N/R50, N/R50lopro, and N/R40 treatment groups. Specifically this is to test whether there is significant difference in the average life expectancy within the N/N85, N/R50, N/R50lopro and N/R40 treatment groups. As this value has been calculated, we may say: The calculated partial F-statistic is 37.3 with p-value near zero (< 2.2e-16). This is evidence to support using the full model in lieu of the reduced model, at the $\alpha = 0.05$ level, such that we have evidence to support the conclusion that there is significant difference among the N/N85, N/R50, N/R50lopro and N/R40 treatment group means in average life expectancy in this experiment.

\newpage 

## g)

Consider an F-statistic of the form given on slide 20 of slide set 2. Provide the $\boldsymbol{C}$ matrix and $\boldsymbol{d}$ vector and compute the F-statistic corresponding to the test of the hypotheses in part (e).

```{r}
# Touch this up
y <- case0501$Lifetime
I <- diag(1, length(y))
r <- length(levels(case0501$Diet)) 
xmat <- model.matrix(~0 + case0501$Diet)
proj <- function(x){x %*% MASS::ginv(t(x)%*%x) %*% t(x)}
hat.sig2 <- t(y) %*% (I-proj(xmat)) %*% y / (length(y)-r) 
hat.b <- solve(t(xmat)%*%xmat) %*% t(xmat) %*% y 
C <- matrix(c(1, -1, 0, 0, 0, 0,
              1, 0, -1, 0, 0, 0,
              1, 0, 0, 0, 0, -1), 
            byrow = TRUE, 
            nrow = 3)
Fstat <- t(C %*% hat.b) %*% solve(C %*% solve(t(xmat)%*%xmat) %*% t(C)) %*% (C %*% hat.b)/3/hat.sig2
Fstat[[1]]
```

$$
H_0: C\boldsymbol{\beta} = \mathbf{d}
$$

$$
H_a: C\boldsymbol{\beta} \neq \mathbf{d}
$$

where,

$$
C = 
\begin{bmatrix}
1 & -1 & 0 & 0 & 0 & 0 \\
1 & 0 & -1 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & -1
\end{bmatrix}
$$
And: 

$\mathbf{d} = \mathbf{0} = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}$

Again, we have 3 degrees of freedom difference in the full vs. reduced model, meaning we use $q = 3$ in the following equation: 

$$
F = \frac{(C\hat{\boldsymbol{\beta}} - \mathbf{d})' (C (\mathbf{X}'\mathbf{X})^{-1} C')^{-1} (C\hat{\boldsymbol{\beta}} - \mathbf{d}) / q}{\hat{\sigma}^2}
$$

and

$$
\hat{\boldsymbol{\beta}} = (\mathbf{X}'\mathbf{X})^{-1} \mathbf{X}'\mathbf{y}, \quad \hat{\sigma}^2 = \frac{\mathbf{y}' (\mathbf{I} - P_{\mathbf{X}}) \mathbf{y}}{n - r}
$$

From the code and output below, $F = 37.3$, the same result as in part e), and having similar interpretation within the context of the study. 

\newpage 

## h)

Use R to obtain the p-value associated with the F-statistic in part g). Provide the interpretation of the p-value. That is, what probability does it reflect? If you are not sure what I am looking for, **pick up any undergraduate Statistics textbook for examples.** (Sick burn)

```{r}
p_value <- 1 - pf(q = Fstat[[1]], 
                  df1 = 3, 
                  df2 = length(y) - r)
p_value
```

Again, similar to part f), the p-value is practically zero, in fact it is rounded to 0 via the method used. 

The p-value represents the probability of obtaining an F-statistic as extreme as 37.3 (or more extreme) under the null hypothesis being true.

\newpage 

## i)

Evaluate the strength of evidence against the null hypothesis based on the p-value found in part (h). Do not use the p-value to make a decision about rejecting or failing to reject the null hypothesis - I am not interested in that. For more background reading, consider the following reference: [https://www.amstat.org/asa/files/pdfs/p-valuesstatement.pdf](https://www.amstat.org/asa/files/pdfs/p-valuesstatement.pdf).

The p-value from part h) is extremely small ($p < 0.001$), indicating extremely strong evidence against $H_0: C\boldsymbol{\beta} = \boldsymbol{0}$.

\newpage 

# Problem 2

Consider a two-factor experiment with factors A and B. Factor A represents gender and has two levels (male coded as 1/female coded as 2). Factor B reflects a patient's smoking history and has four levels (never coded as 1, light coded as 2, median coded as 3, heavy coded as 4). The data set contains a third variable, `fat`, which we will ignore for this analysis. Let the response variable, `exercise`, denote the patient's achievement score in some exercise routine that can be used as a proxy for cardiovascular fitness. The higher the score, the better the patient's cardiovascular fitness. The data are saved in a text file `stress.txt`. You may use R or SAS to analyze these data, but you have to submit all your code and results. (I will present my solution using SAS.) We will fit a cell-means model to these data estimating a patient's achievement score based on gender and smoking history.

## Note: 

Doing this problem primarily in R, again.  

```{r}
stress <- read.table(file = "stress.txt", 
                     header = TRUE, 
                     sep = ",")
```

## a)

Set up a contingency table similar to the one on slide 7 of the lecture slides that reflects all possible factor level combinations. Use the parameterization introduced on slide 6 of the same set of slides and specify each cell mean.

```{r}
require(dplyr)
require(tidyverse)

aggStress <- stress |>
  group_by(gender, smoking) |>
  summarise(meanScore = mean(Score), .groups = "drop")

stressTable <- aggStress |>
  pivot_wider(names_from = smoking, values_from = meanScore, names_prefix = "Smoking_")

round(stressTable, 2)
```

\newpage 

## b)

Specify the model matrix for this model. (I realize this is a big matrix and I will ask you to do this only once.)

2 Genders, 4 levels of smoking, 3 reps of each gender-smoking combination. 

This means our model matrix (design matrix) has 8 columns and 24 rows. 

This looks like: 

$$
X =
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
$$

Weeeeee! 

\newpage 

## c)

Specify the corresponding $\boldsymbol{\beta}$-vector and obtain its OLS estimate.

```{r}
gender <- rep(c("Male", "Female"), each = 12)  
smoking <- rep(c("Never", "Light", "Medium", "Heavy"), each = 3, times = 2)

stressDat <- data.frame(gender = factor(gender), smoking = factor(smoking))
X <- model.matrix(~ 0 + gender:smoking, data = stressDat)
X <- X[, order(colnames(X))]

y <- stress$Score  

beta_hat <- solve(t(X) %*% X) %*% (t(X) %*% y)

# X[0,]
round(beta_hat,2)
```

\newpage 

## d)

Obtain the standard error associated with the OLS estimator of each cell mean. Start by specifying the relevant formula and show your calculations at least once, i.e., for at least one of the cell means.

$$
\text{SE}(\hat{\beta}_j) = \sqrt{\sigma^2 \cdot [(\mathbf{X}'\mathbf{X})^{-1}]_{jj}}
$$

where $\hat{\beta}_j$ is the OLS estimate for cell mean $j$ and $\sigma^2$ is the estimated residual variance, given by:

$$
\hat{\sigma}^2 = \frac{\mathbf{y}'(\mathbf{I} - \mathbf{P}_X) \mathbf{y}}{n - p}
$$

where $\mathbf{I}$ is the identity matrix, $\mathbf{P}_X = \mathbf{X}(\mathbf{X}'\mathbf{X})^{-1} \mathbf{X}'$ is the projection matrix, $n$ is the number of observations, and $p$ is the number of estimated parameters (cells).

Each diagonal element of $(\mathbf{X}'\mathbf{X})^{-1}$ determines the variance of $\hat{\beta}_j$, meaning that:

$$
\text{Var}(\hat{\beta}_j) = \sigma^2 \cdot [(\mathbf{X}'\mathbf{X})^{-1}]_{jj}
$$

For the first cell mean (e.g., Male, Never Smoked):

$$
\text{SE}(\hat{\beta}_1) = \sqrt{\hat{\sigma}^2 \cdot [(\mathbf{X}'\mathbf{X})^{-1}]_{11}}
$$

```{r}
require(dplyr)

n <- nrow(X) 
p <- ncol(X) 
I <- diag(1, n)  

P_X <- X %*% solve(t(X) %*% X) %*% t(X)
sigma2_hat <- as.numeric(t(y) %*% (I - P_X) %*% y / (n - p))
var_beta_hat <- sigma2_hat * solve(t(X) %*% X)
SE_beta_hat <- sqrt(diag(var_beta_hat))
names(SE_beta_hat) <- colnames(X)

SE_beta_hat
```

Note: Because we have a balanced design, the SE of each $\hat{\beta}$ is the same. 

\newpage 

## e)

Specify the parameter representation reflecting the main effect of gender and also its point estimate.

```{r}
beta_hat_values <- as.numeric(beta_hat)  

main_effect_gender <- mean(beta_hat_values[1:4] - beta_hat_values[5:8])

main_effect_gender
```

We define the main effect of gender as:

$$
\alpha_G = \frac{1}{4} \sum_{s} \left( \beta_{\text{Male}, s} - \beta_{\text{Female}, s} \right)
$$

Let $\boldsymbol{\beta}$ be the vector of cell means:

$$
\boldsymbol{\beta} =
\begin{bmatrix}
\beta_{\text{Female}, \text{Never}} \\
\beta_{\text{Female}, \text{Light}} \\
\beta_{\text{Female}, \text{Medium}} \\
\beta_{\text{Female}, \text{Heavy}} \\
\beta_{\text{Male}, \text{Never}} \\
\beta_{\text{Male}, \text{Light}} \\
\beta_{\text{Male}, \text{Medium}} \\
\beta_{\text{Male}, \text{Heavy}}
\end{bmatrix}
$$

We express the main effect of gender as a linear contrast:

$$
\alpha_G = \mathbf{C} \boldsymbol{\beta}
$$

where the contrast matrix $\mathbf{C}$ is:

$$
\mathbf{C} =
\begin{bmatrix}
\frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4} 
\end{bmatrix}
$$

Thus, the main effect of gender can be written in matrix form as:

$$
\alpha_G = 
\begin{bmatrix}
\frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4} 
\end{bmatrix}
\boldsymbol{\beta}
$$

```{r}
C <- matrix(c(1/4, 1/4, 1/4, 1/4, -1/4, -1/4, -1/4, -1/4), nrow = 1)
beta_hat
C %*% beta_hat
```

This representation shows that the main effect is computed as a weighted sum of the cell means, ensuring an equal-weighted mean difference across smoking levels.

\newpage 

## f)

Is there an interaction between gender and smoking? Similarly to the previous parts, specify all relevant parameter representations.

$H_0$: No Interaction

$$
(\mu_{\text{Male}, s} - \mu_{\text{Female}, s}) - (\mu_{\text{Male}, s'} - \mu_{\text{Female}, s'}) = 0 \quad \text{for all } s \neq s'
$$

where $\mu_{\text{Male}, s}$ is the mean exercise score for males at smoking level s, $\mu_{\text{Female}, s}$ is the mean exercise score for females at smoking level s.

This hypothesis states that the difference between genders must be the same at all smoking levels.

We have our same  vector of cell means:

$$
\boldsymbol{\mu} =
\begin{bmatrix}
\mu_{\text{Female}, \text{Never}} \\
\mu_{\text{Female}, \text{Light}} \\
\mu_{\text{Female}, \text{Medium}} \\
\mu_{\text{Female}, \text{Heavy}} \\
\mu_{\text{Male}, \text{Never}} \\
\mu_{\text{Male}, \text{Light}} \\
\mu_{\text{Male}, \text{Medium}} \\
\mu_{\text{Male}, \text{Heavy}}
\end{bmatrix}
$$

To test for no interaction, we use the contrast matrix:

$$
\mathbf{C}_{\text{int}} =
\begin{bmatrix}
1 & -1 &  0 &  0 & -1 &  1 &  0 &  0 \\
1 &  0 & -1 &  0 & -1 &  0 &  1 &  0 \\
1 &  0 &  0 & -1 & -1 &  0 &  0 &  1
\end{bmatrix}
$$

Thus, testing for interaction involves checking:

$$
\mathbf{C}_{\text{int}} \boldsymbol{\mu} = \mathbf{0}
$$

$$
\begin{bmatrix}
1 & -1 &  0 &  0 & -1 &  1 &  0 &  0 \\
1 &  0 & -1 &  0 & -1 &  0 &  1 &  0 \\
1 &  0 &  0 & -1 & -1 &  0 &  0 &  1
\end{bmatrix}
\begin{bmatrix}
\mu_{\text{Female}, \text{Never}} \\
\mu_{\text{Female}, \text{Light}} \\
\mu_{\text{Female}, \text{Medium}} \\
\mu_{\text{Female}, \text{Heavy}} \\
\mu_{\text{Male}, \text{Never}} \\
\mu_{\text{Male}, \text{Light}} \\
\mu_{\text{Male}, \text{Medium}} \\
\mu_{\text{Male}, \text{Heavy}}
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
$$

```{r}
C <- matrix(c(1, -1, 0, 0, -1, 1, 0, 0,
              1, 0, -1, 0, -1, 0, 1, 0,
              1, 0, 0, -1, -1, 0, 0, 1), nrow = 3)
# C_int <- matrix(c(
#   3/4, -1/4, -1/4, -1/4, -3/4,  1/4,  1/4,  1/4,
#  -1/4,  3/4, -1/4, -1/4,  1/4, -3/4,  1/4,  1/4,
#  -1/4, -1/4,  3/4, -1/4,  1/4,  1/4, -3/4,  1/4,
#  -1/4, -1/4, -1/4,  3/4,  1/4,  1/4,  1/4, -3/4
# ), nrow = 4, byrow = TRUE)

# \mathbf{C}_{\text{int}} =
# \begin{bmatrix}
# \frac{3}{4} & -\frac{1}{4} & -\frac{1}{4} & -\frac{1}{4} & -\frac{3}{4} & \frac{1}{4} & \frac{1}{4} & \frac{1}{4} \\
# -\frac{1}{4} & \frac{3}{4} & -\frac{1}{4} & -\frac{1}{4} & \frac{1}{4} & -\frac{3}{4} & \frac{1}{4} & \frac{1}{4} \\
# -\frac{1}{4} & -\frac{1}{4} & \frac{3}{4} & -\frac{1}{4} & \frac{1}{4} & \frac{1}{4} & -\frac{3}{4} & \frac{1}{4} \\
# -\frac{1}{4} & -\frac{1}{4} & -\frac{1}{4} & \frac{3}{4} & \frac{1}{4} & \frac{1}{4} & \frac{1}{4} & -\frac{3}{4}
# \end{bmatrix}

 
C %*% beta_hat 
```

These values are not zero! So there is some evidence, no comment on strength, to suppose there are interaction effects. 

\newpage 

## g)

Specify $\boldsymbol{C}$ allowing you to test for a main effect of gender. State the appropriate null- and alternative hypothesis using parameter representation. Obtain the corresponding value of the test statistic, df and p-value and provide a conclusion in the context of the data.

The hypotheses: 

$$
H_0: \alpha_G = 0
$$

$$
H_A: \alpha_G \neq 0
$$

Using our parameter representation from part e), the main effect of gender is:

$$
\alpha_G = \frac{1}{4} \sum_{s} \left( \beta_{\text{Male}, s} - \beta_{\text{Female}, s} \right)
$$

Thus, the null hypothesis states that the mean exercise score for males and females is the same on average across smoking levels, while the alternative hypothesis states that there is a difference in mean exercise score between genders.

To test for the main effect of gender, we define the contrast matrix:

$$
\mathbf{C} =
\begin{bmatrix}
\frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4} 
\end{bmatrix}
$$

Testing for the main effect of gender involves solving:

$$
\mathbf{C} \boldsymbol{\beta} = 0
$$

$$
\begin{bmatrix}
\frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4}  & -\frac{1}{4} 
\end{bmatrix}
\begin{bmatrix}
\beta_{\text{Female}, \text{Never}} \\
\beta_{\text{Female}, \text{Light}} \\
\beta_{\text{Female}, \text{Medium}} \\
\beta_{\text{Female}, \text{Heavy}} \\
\beta_{\text{Male}, \text{Never}} \\
\beta_{\text{Male}, \text{Light}} \\
\beta_{\text{Male}, \text{Medium}} \\
\beta_{\text{Male}, \text{Heavy}}
\end{bmatrix}
=
0
$$

The test statistic for testing $H_0: \alpha_G = 0$ is:

$$
F = \frac{(\mathbf{C} \hat{\boldsymbol{\beta}})' (\mathbf{C} (\mathbf{X}' \mathbf{X})^{-1} \mathbf{C}')^{-1} (\mathbf{C} \hat{\boldsymbol{\beta}})}{\hat{\sigma}^2 q}
$$

where $\hat{\boldsymbol{\beta}}$ is the vector of estimated cell means, $(\mathbf{X}' \mathbf{X})^{-1}$ is the covariance matrix of $\hat{\boldsymbol{\beta}}$, q = 1 (number of constraints tested), and $\hat{\sigma}^2$ is the residual variance estimate.

The numerator degrees of freedom: $df_{\text{num}} = 1$, since we are testing a single contrast.

The denominator degrees of freedom: $df_{\text{den}} = n - p$, where n is the total number of observations and p = 8 (one parameter for each gender-smoking combination).

```{r}
C_gender <- matrix(c(1/4, 1/4, 1/4, 1/4, -1/4, -1/4, -1/4, -1/4), nrow = 1)

num <- t(C_gender %*% beta_hat) %*% solve(C_gender %*% solve(t(X) %*% X) %*% t(C_gender)) %*% (C_gender %*% beta_hat)
den <- sigma2_hat * 1  
F_stat <- num / den

df_num <- 1
df_den <- nrow(X) - ncol(X)

p_value <- 1 - pf(F_stat, df_num, df_den)

list(F_stat = F_stat, df_num = df_num, df_den = df_den, p_value = p_value)
```

\newpage 

## h)

Specify $\boldsymbol{C}$ allowing you to test for a main effect of smoking. State the appropriate null- and alternative hypothesis using parameter representation. Obtain the corresponding value of the test statistic, df and p-value and provide a conclusion in the context of the data.

To test the main effect of smoking, we have:

$$
H_0: \alpha_S = 0
$$

$$
H_A: \alpha_S \neq 0
$$

where the main effect of smoking is:

$$
\alpha_S(s) = \frac{1}{2} \sum_{g} \left( \beta_{g, s} - \bar{\beta}_S \right), \quad \text{for } s = \text{Never, Light, Medium, Heavy}
$$

To test for the main effect of smoking, define:

$$
\mathbf{C} =
\begin{bmatrix}
1 & -1 &  0 &  0 & 1 & -1 &  0 &  0 \\
1 &  0 & -1 &  0 & 1 &  0 & -1 &  0 \\
1 &  0 &  0 & -1 & 1 &  0 &  0 & -1
\end{bmatrix}
$$

Solving:

$$
\mathbf{C} \boldsymbol{\beta} = 0
$$

$$
\begin{bmatrix}
1 & -1 &  0 &  0 & 1 & -1 &  0 &  0 \\
1 &  0 & -1 &  0 & 1 &  0 & -1 &  0 \\
1 &  0 &  0 & -1 & 1 &  0 &  0 & -1
\end{bmatrix}
\begin{bmatrix}
\beta_{\text{Female}, \text{Never}} \\
\beta_{\text{Female}, \text{Light}} \\
\beta_{\text{Female}, \text{Medium}} \\
\beta_{\text{Female}, \text{Heavy}} \\
\beta_{\text{Male}, \text{Never}} \\
\beta_{\text{Male}, \text{Light}} \\
\beta_{\text{Male}, \text{Medium}} \\
\beta_{\text{Male}, \text{Heavy}}
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
$$

$$
F = \frac{(\mathbf{C} \hat{\boldsymbol{\beta}})' (\mathbf{C} (\mathbf{X}' \mathbf{X})^{-1} \mathbf{C}')^{-1} (\mathbf{C} \hat{\boldsymbol{\beta}})}{\hat{\sigma}^2 q}
$$

where q = 3 (since we test 3 independent constraints), and $\hat{\sigma}^2$ is the residual variance.

Numerator: $df_{\text{num}} = 3$ (corresponding to the 3 constraints).
Denominator: $df_{\text{den}} = n - p$, where n is total observations and p = 8 (one parameter per gender-smoking combination).


```{r}
C_smoking <- matrix(c(1, -1,  0,  0, 1, -1,  0,  0,
                      1,  0, -1,  0, 1,  0, -1,  0,
                      1,  0,  0, -1, 1,  0,  0, -1), 
                    nrow = 3, byrow = TRUE)

num <- t(C_smoking %*% beta_hat) %*% solve(C_smoking %*% solve(t(X) %*% X) %*% t(C_smoking)) %*% (C_smoking %*% beta_hat)
den <- sigma2_hat * 3  
F_stat <- num / den

df_num <- 3
df_den <- nrow(X) - ncol(X)

p_value <- 1 - pf(F_stat, df_num, df_den)

list(F_stat = F_stat, df_num = df_num, df_den = df_den, p_value = p_value)
```

\newpage 

## i)

Specify $\boldsymbol{C}$ allowing you to test for an interaction between gender and smoking. State the appropriate null- and alternative hypothesis using parameter representation. Obtain the value of the relevant test statistic, df and p-value. Provide an interpretation of the result that a scientist unfamiliar with technical statistical terms can understand. Would you argue that the interaction is of practical importance? Briefly explain.

To test for an interaction effect between gender and smoking, we set up:

$$
H_0: \gamma_s = 0, \quad \forall s
$$

$$
H_A: \gamma_s \neq 0 \text{ for at least one } s
$$

where the interaction effect is:

$$
\gamma_s = (\beta_{\text{Male}, s} - \beta_{\text{Female}, s}) - \alpha_G, \quad \text{for } s = \text{Never, Light, Medium, Heavy}
$$

where $\beta_{\text{Male}, s}$ and $\beta_{\text{Female}, s}$ are the mean exercise scores for Males and Females at smoking level s, and $\alpha_G$ is the main effect of gender, defined as the average difference in means across all smoking levels.

Thus, the null hypothesis states that the difference between males and females is the same across all smoking levels, while the alternative hypothesis states that the effect of gender depends on smoking level, indicating an interaction.

To test for the interaction effect, we define:

$$
\mathbf{C}_{\text{int}} =
\begin{bmatrix}
1 & -1 &  0 &  0 & -1 &  1 &  0 &  0 \\
1 &  0 & -1 &  0 & -1 &  0 &  1 &  0 \\
1 &  0 &  0 & -1 & -1 &  0 &  0 &  1
\end{bmatrix}
$$

Thus, testing for an interaction involves solving:

$$
\mathbf{C}_{\text{int}} \boldsymbol{\beta} = 0
$$

$$
\begin{bmatrix}
1 & -1 &  0 &  0 & -1 &  1 &  0 &  0 \\
1 &  0 & -1 &  0 & -1 &  0 &  1 &  0 \\
1 &  0 &  0 & -1 & -1 &  0 &  0 &  1
\end{bmatrix}
\begin{bmatrix}
\beta_{\text{Female}, \text{Never}} \\
\beta_{\text{Female}, \text{Light}} \\
\beta_{\text{Female}, \text{Medium}} \\
\beta_{\text{Female}, \text{Heavy}} \\
\beta_{\text{Male}, \text{Never}} \\
\beta_{\text{Male}, \text{Light}} \\
\beta_{\text{Male}, \text{Medium}} \\
\beta_{\text{Male}, \text{Heavy}}
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0 \\
\end{bmatrix}
$$

$$
F = \frac{(\mathbf{C}_{\text{int}} \hat{\boldsymbol{\beta}})' (\mathbf{C}_{\text{int}} (\mathbf{X}' \mathbf{X})^{-1} \mathbf{C}_{\text{int}}')^{-1} (\mathbf{C}_{\text{int}} \hat{\boldsymbol{\beta}})}{\hat{\sigma}^2 q}
$$

where q = 3 (testing 3 independent constraints) and $\hat{\sigma}^2$ is the residual variance estimate.

Numerator: $df_{\text{num}} = 3$ (corresponding to the 3 constraints).
Denominator: $df_{\text{den}} = n - p$, where: n is total observations and p = 8 (one parameter per gender-smoking combination).

```{r, eval = FALSE, echo = FALSE}
C_interaction <- matrix(c(1, -1, 0, 0, -1, 1, 0, 0, 
              1, 0, -1, 0, -1, 0, 1, 0, 
              1, 0, 0, -1, -1, 0, 0, 1), nrow = 3)

num <- t(C_interaction %*% beta_hat) %*% ginv(C_interaction %*% solve(t(X) %*% X) %*% t(C_interaction)) %*% (C_interaction %*% beta_hat)

den <- sigma2_hat * 3  # q = 3
F_stat <- num / den

df_num <- 3
df_den <- nrow(X) - ncol(X)

p_value <- 1 - pf(F_stat, df_num, df_den)

list(F_stat = F_stat, df_num = df_num, df_den = df_den, p_value = p_value)
```

```{r}
# require(MASS)
# 
# C_interaction <- matrix(c(3/4, -1/4, -1/4, -1/4, -3/4, 1/4, 1/4, 1/4,
#                           -1/4, 3/4, -1/4, -1/4, 1/4, -3/4, 1/4, 1/4,
#                           -1/4, -1/4, 3/4, -1/4, 1/4, 1/4, -3/4, 1/4,
#                           -1/4, -1/4, -1/4, 3/4, 1/4, 1/4, 1/4, -3/4), 
#                         nrow = 4, byrow = TRUE)
# 
# # qr(C_interaction)$rank
# # qr(X)$rank
# # solve_safe <- ginv(C_interaction %*% solve(t(X) %*% X) %*% t(C_interaction))
# 
# num <- t(C_interaction %*% beta_hat) %*% ginv(C_interaction %*% solve(t(X) %*% X) %*% t(C_interaction)) %*% (C_interaction %*% beta_hat)
# 
# den <- sigma2_hat * 3  # q = 3
# F_stat <- num / den
# 
# df_num <- 3
# df_den <- nrow(X) - ncol(X)
# 
# p_value <- 1 - pf(F_stat, df_num, df_den)
# 
# list(F_stat = F_stat, df_num = df_num, df_den = df_den, p_value = p_value)
```

### Interpretation: 

If $p < 0.05$, there is strong evidence of interaction.

If $p \geq 0.05$, there is no strong evidence that gender effects depend on smoking level.

Practical Importance? Depends on effect size—if differences are small, it may not matter.

We investigated whether gender and smoking history interact to influence exercise performance. In simpler terms, we wanted to see if the difference in exercise scores between males and females depends on smoking level.

If there is no interaction, this means that the difference between males and females is the same across all smoking levels—for example, if males consistently outperform females by a fixed amount, regardless of smoking habits.

If there is an interaction, this means that the gender gap in exercise scores changes depending on smoking level—for instance, perhaps males and females have similar scores for light smokers, but heavy smoking reduces male performance more than female performance.

\newpage 

## j)

Provide a 95% confidence interval for the mean associated with male patients who never smoked. 
Show all your work.

$$
c^T \hat{\boldsymbol{\beta}} \pm t_{n-r, 1-\alpha/2} \sqrt{\hat{\sigma}^2 c^T (\mathbf{X}^T \mathbf{X})^{-1} c}
$$

where:
- $c^T \hat{\boldsymbol{\beta}}$ is the estimated mean for male patients who never smoked.
- $t_{n-r, 1-\alpha/2}$ is the critical value from the t-distribution with degrees of freedom $df = n - r$.
- $\hat{\sigma}^2$ is the estimated variance from the residual mean square.
- $(\mathbf{X}^T \mathbf{X})^{-1}$ is the inverse of the information matrix.

Given the estimated mean $\hat{\beta}$ for the category Male, Never Smoked, the confidence interval follows:

$$
\hat{\beta} \pm t_{n-r, 1-\alpha/2} \times \text{SE}
$$

where:
- $\hat{\beta}$ is the estimated mean for male patients who never smoked.
- $t_{n-r, 1-\alpha/2}$ is the critical t-value from the Student’s $t$-distribution.
- SE is the standard error of the estimated mean.
- $n$ is the total number of observations, and $r$ is the number of estimated parameters.

The 95% confidence interval for the mean achievement score for male patients who never smoked is:

$$
(\hat{\beta} - \text{MOE}, \hat{\beta} + \text{MOE})
$$

This interval provides the range within which we are 95% confident that the true population mean lies.

```{r}
stress <- read.table(file = "stress.txt", 
                     header = TRUE, 
                     sep = ",")

stress_data <- stress 

stress_data$gender <- as.factor(stress_data$gender)
stress_data$smoking <- as.factor(stress_data$smoking)

model <- lm(Score ~ gender:smoking - 1, data = stress_data)

beta_male_never <- coef(model)["gender1:smoking2"]
se_male_never <- summary(model)$coefficients["gender1:smoking2", "Std. Error"]

df <- df.residual(model)

t_value <- qt(0.975, df)

MOE <- t_value * se_male_never

CI_lower <- beta_male_never - MOE
CI_upper <- beta_male_never + MOE

cat("95% Confidence Interval for Male, Never Smoked: (", 
    round(CI_lower, 2), ",", round(CI_upper, 2), ")\n")
```


\newpage 

## k)

Provide a 95% confidence interval for the mean effect of gender. Show all your work.

$$
c^T \hat{\boldsymbol{\beta}} \pm t_{n-r, 1-\alpha/2} \sqrt{\hat{\sigma}^2 c^T (\mathbf{X}^T \mathbf{X})^{-1} c}
$$

where:
- $c^T \hat{\boldsymbol{\beta}}$ represents the estimated gender effect.
- $t_{n-r, 1-\alpha/2}$ is the critical value from the t-distribution with degrees of freedom $df = n - r$.
- $\hat{\sigma}^2$ is the estimated variance from the residual mean square.
- $(\mathbf{X}^T \mathbf{X})^{-1}$ is the inverse of the information matrix.

The mean effect of gender can be computed as the difference between the mean achievement scores for male and female patients:

$$
\hat{\delta} = \hat{\beta}_{\text{Male}} - \hat{\beta}_{\text{Female}}
$$

The confidence interval follows:

$$
\hat{\delta} \pm t_{n-r, 1-\alpha/2} \times SE
$$

where:
- $\hat{\delta}$ is the estimated gender effect.
- $t_{n-r, 1-\alpha/2}$ is the critical t-value from the Student’s $t$-distribution.
- SE is the standard error of the gender effect estimate.
- $n$ is the total number of observations, and $r$ is the number of estimated parameters.

The 95% confidence interval for the mean effect of gender is:

$$
(\hat{\delta} - \text{MOE}, \hat{\delta} + \text{MOE})
$$

This interval provides the range within which we are 95% confident that the true gender effect on the mean achievement score lies.

```{r}
stress <- read.table(file = "stress.txt", 
                     header = TRUE, 
                     sep = ",")

stress_data <- stress 
stress_data$gender <- as.factor(stress_data$gender)
stress_data$smoking <- as.factor(stress_data$smoking)

model <- lm(Score ~ gender:smoking - 1, data = stress_data)

beta_male <- mean(coef(model)[grep("gender1:", names(coef(model)))])
beta_female <- mean(coef(model)[grep("gender2:", names(coef(model)))])

gender_effect <- beta_male - beta_female

se_male <- mean(summary(model)$coefficients[grep("gender1:", rownames(summary(model)$coefficients)), "Std. Error"])
se_female <- mean(summary(model)$coefficients[grep("gender2:", rownames(summary(model)$coefficients)), "Std. Error"])

se_gender_effect <- sqrt(se_male^2 + se_female^2)

df <- df.residual(model)

t_value <- qt(0.975, df)

MOE <- t_value * se_gender_effect

CI_lower <- gender_effect - MOE
CI_upper <- gender_effect + MOE

cat("95% Confidence Interval for Gender Effect: (", 
    round(CI_lower, 2), ",", round(CI_upper, 2), ")\n")
```

\newpage 

## l)

Obtain the residuals for the fitted models and use them to check the necessary assumptions that allow us to fit the proposed model. Please submit and explain any graphical displays that you might use.

```{r}
stress_data <- stress 

stress_data$gender <- as.factor(stress_data$gender)
stress_data$smoking <- as.factor(stress_data$smoking)

# Fit the cell-means model
model <- lm(Score ~ gender:smoking - 1, data = stress_data)

# Extract residuals and fitted values
residuals <- resid(model)
fitted_values <- fitted(model)
```

```{r}
library(MASS)
stdresids <- studres(model) 

plot(model$fitted.values, stdresids, main = "Studentized Residuals vs Fitted Values", xlab = "Fitted Values", ylab = "Studentized Residuals")
abline(h = 0, col = "red")
qqnorm(stdresids)
qqline(stdresids, col = "black")

# shapiro.test()
```

```{r}
hist(stdresids, main="Histogram of Residuals", xlab="Residuals", breaks=10)
```

The residual plot (studentized) looks good for the purposes of diagnosing the model assumptions, insomuch as it appears to be randomly spread (constant variance) and centered around zero. 

The QQ plot does not closely align with the reference line within the first theoretical quantile, so there are some concerns about the normality distribution, even with considering the studentized residuals. Furthermore, the QQ plot appears to have a slight "S" shape/curve, further suggesting deviation from normality. The histogram of residuals (including studentized) provide a similar picture. 

Furthermore, via review of the residual plot (by fitted values) we generally observe a random spread of residuals across the range of fitted values (there is not a clear trend present in the residual plot above). We do not observe any trends or noticeable patterns in the above plots, such that we have reason to believe our linearity assumption is not being violated. 

Overall, we have reason to suspect our normality assumption is being violated but the other assumptions appear appropriate. 
