---
title: "HW9"
output: pdf_document
author: "Sam Olson"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

# Q1 

A plant scientist was interested in comparing two plant genotypes (1 and 2). An experiment was conducted in a greenhouse with one table, eight trays, and sixteen pots. The table in the greenhouse held the eight trays with two pots on each tray. For each of the eight trays, two genotype 1 seeds were planted in one pot, and two genotype 2 seeds were planted in the other pot. The assignment of genotypes 1 and 2 to the two pots within each tray was determined by flipping a fair coin. The response of interest is a quantitative measurement of overall plant health that was calculated for each plant 42 days after planting. These quantitative measurements of overall plant health are presented as integers in Table 1 to make calculations easier, but please answer all questions as if each measurement is a realization from a normal distribution.

Table 1. Measurements of overall plant health for each plant.

| Tray | Genotype 1 Pot |         | Genotype 2 Pot |         |
|------|----------------|---------|----------------|---------|
|      | Plant 1        | Plant 2 | Plant 1        | Plant 2 |
| 1    | 8              | 7       | 6              | 7       |
| 2    | 8              | 9       | 4              | 5       |
| 3    | 8              | 8       | 7              | 7       |
| 4    | 5              | 7       | 4              | 2       |
| 5    | 5              | 6       | 4              | 3       |
| 6    | 9              | 10      | 7              | 9       |
| 7    | 5              | 7       | 1              | 4       |
| 8    | 4              | 6       | 5              | 5       |

Let $i$ index genotypes ($i = 1, 2$), $j$ index trays ($j = 1, \ldots, 8$), and $k$ index plants within pots ($k = 1, 2$). Let $y_{ijk}$ denote the response corresponding to genotype $i$, tray $j$, and plant $k$. Suppose:

$$
y_{ijk} = \mu_i + t_j + p_{ij} + e_{ijk} \quad \forall \, i, j, k,
$$

where $\mu_1$ and $\mu_2$ are unknown real-valued parameters, $t_j \sim \mathcal{N}(0, \sigma_t^2) \quad \forall \, j$, $p_{ij} \sim \mathcal{N}(0, \sigma_p^2) \quad \forall \, i, j$, $e_{ijk} \sim \mathcal{N}(0, \sigma_e^2) \quad \forall \, i, j, k$, and all $t_j$, $p_{ij}$, $e_{ijk}$ terms are mutually independent.

\newpage 

## a)

Explain what the $p_{ij}$ terms represent and provide one reason for including them in the model.

### Answer

The $p_{ij}$ terms are random effects corresponding to pots, specifically the pot receiving genotype i on tray j.

Design-based rationale: The inclusion of the pot random effect is important to include because each pot is the experimental unit to which a genotype treatment is applied, and there are two observations per pot (one per plant). Specifying this as a random effect allows the model to account for possible variability brought about by sharing the same external conditions experienced by two different plants in the same pot, and allows us to more effectively partition the sources of variation between observations, specifically accounting for possible correlation (and variability) between measurements within the same pot, which is expected to be higher than the correlation (and variability) between plants from different pots. Though this would be expected to increase the overall variability in the model, it should improve estimation of quantities of interest (including contrasts) by more appropriately accounting for possible variation and their sources. 

## b)

Let $\bar{y}_{ij} = \frac{1}{2} \sum_{k=1}^2 y_{ijk} \quad \forall \, i, j$. Determine the distribution of $\bar{y}_{11} - \bar{y}_{21}$.

### Answer

Linear combinations of normal random variables are normal, so $\bar{y}_{11} - \bar{y}_{21}$ will be normally distributed. We then need only find the mean and variance to uniquely characterize the distribution. 

To that end, note: 

$$
\bar{y}_{11\cdot} - \bar{y}_{21\cdot} = \mu_1 - \mu_2 + p_{11} - p_{21} + \bar{e}_{11\cdot} - \bar{e}_{21\cdot}
$$

Thus,

$$
\begin{aligned}
E(\bar{y}_{11\cdot} - \bar{y}_{21\cdot})
&= \mu_1 - \mu_2 + E(p_{11}) - E(p_{21}) + E(\bar{e}_{11\cdot}) - E(\bar{e}_{21\cdot}) \\
&= \mu_1 - \mu_2
\end{aligned}
$$

And: 

$$
\begin{aligned}
\text{Var}(\bar{y}_{11\cdot} - \bar{y}_{21\cdot})
&= \text{Var}(p_{11} - p_{21}) + \text{Var}(\bar{e}_{11\cdot} - \bar{e}_{21\cdot}) \\
&= \text{Var}(p_{11}) + \text{Var}(p_{21}) + \text{Var}(\bar{e}_{11\cdot}) + \text{Var}(\bar{e}_{21\cdot}) \\
&= \sigma_p^2 + \sigma_p^2 + \frac{1}{2}\sigma_e^2 + \frac{1}{2}\sigma_e^2 \\
&= 2\sigma_p^2 + \sigma_e^2
\end{aligned}
$$

Taken together, we have: 

$$
\bar{y}_{11\cdot} - \bar{y}_{21\cdot} \sim N(\mu_1 - \mu_2, 2\sigma_p^2 + \sigma_e^2)
$$

\newpage 

## c)

Compute the value of an unbiased estimator of the variance of $\bar{y}_{11} - \bar{y}_{21}$.

### Answer

Let $d_j = \bar{y}_{1j\cdot} - \bar{y}_{2j\cdot} \forall j$. 

From part b), it follows:

$$
d_1, \ldots, d_8 \overset{iid}{\sim} N(\mu_1 - \mu_2, 2\sigma_p^2 + \sigma_e^2)
$$

Thus,

$$
s_d^2 = \sum_{j=1}^8 (d_j - \bar{d}_{\cdot})^2 / (8-1)
$$

is an unbiased estimator of $2\sigma_p^2 + \sigma_e^2$. 

Calculating: 

```{r}
plant_data_wide <- data.frame(
  Tray = 1:8,
  G1_P1 = c(8, 8, 8, 5, 5, 9, 5, 4),
  G1_P2 = c(7, 9, 8, 7, 6, 10, 7, 6),
  G2_P1 = c(6, 4, 7, 4, 4, 7, 1, 5),
  G2_P2 = c(7, 5, 7, 2, 3, 9, 4, 5)
)

plant_data_wide$d_j <- rowMeans(plant_data_wide[, c("G1_P1", "G1_P2")]) -
                       rowMeans(plant_data_wide[, c("G2_P1", "G2_P2")])

d_bar <- mean(plant_data_wide$d_j)

s_d_squared <- sum((plant_data_wide$d_j - d_bar)^2) / (length(plant_data_wide$d_j) - 1)
s_d_squared
```

$$
s_d^2 = 13.5/7 \approx 1.929
$$

\newpage 

## d)

Provide a 95% confidence interval for $\mu_1 - \mu_2$.

Plus Interpretation! 

### Answer

```{r}
est <- mean(plant_data_wide$d_j)
moe <- qt(p = 0.975, df = 7)*(sqrt(s_d_squared/8))
```

```{r}
lb <- est - moe
ub <- est + moe
cat("Lower bound:", lb, "\nUpper bound:", ub, "\n")
```

$$
\widehat{\mu_1 - \mu_2}  \pm t_{0.975,7} \sqrt{s_d^2 / 8} \rightarrow  2 \pm (2.36 \cdot 0.49) \rightarrow (0.84, 3.16)
$$

Interpretation: We are 95% confident that the true mean difference in overall plant health between Genotype 1 and Genotype 2 is between 0.84 and 3.16, in the direction of Genotype 1 minus Genotype 2 and using units of "plant health" where higher values indicate greater (positive) health. This indicates that, on average, Genotype 1 plants exhibit higher overall plant health than Genotype 2 plants, based on the linear model averaging over trays, pots, and plants, and accounting for random variability due to trays, pots, and residual error.

## e)

The model can be written in the form $y = X \beta + Z u + e$. Provide $X$, $\beta$, $Z$, and $u$.

### Answer

Assume an order, for convenience: order the response vector $y$ is ordered by tray, with measurements from the genotype 1 pot listed first and those from the genotype 2 pot listed second within each tray.

Doing so gives us: 

$$
\boldsymbol{X} = \mathbf{1}_{8 \times 1} \otimes \mathbf{I}_{2 \times 2} \otimes \mathbf{1}_{2 \times 1}
$$

$$
\boldsymbol{\beta} = (\mu_1, \mu_2)^\top
$$

$$
\boldsymbol{Z} = [\mathbf{I}_{8 \times 8} \otimes \mathbf{1}_{4 \times 1}, \mathbf{I}_{16 \times 16} \otimes \mathbf{1}_{2 \times 1}]
$$

and 

$$
\boldsymbol{u} = [t_1, t_2, \ldots, t_8, p_{11}, p_{21}, p_{12}, p_{22}, \ldots, p_{18}, p_{28}]^\top
$$

\newpage

## f)

Suppose the researchers would like to repeat their experiment again, using the same basic resources: eight trays, two pots per tray, sixteen seeds of genotype 1, and sixteen seeds of genotype 2. Would you recommend any changes to their experimental design? Explain why or why not.

### Answer

Yes, I have a recommendation.

Instead of planting two seeds of the same genotype in each pot, I recommend placing one plant of genotype 1 and one plant of genotype 2 in each of the 16 pots. This would allow for a direct within-pot comparison of the two genotypes, with both plants experiencing the same local environment (same soil, same pot, and same general environment).

This also improves the statistical efficiency of the experiment by reducing the variance of the estimator for the difference in genotype means.

To illustrate this point, consider the original design. 

The variance of the estimated difference between the two genotype means is:

$$
\text{Var}(\bar{y}_{1\cdot\cdot} - \bar{y}_{2\cdot\cdot}) = \frac{2\sigma_p^2 + \sigma_e^2}{8} = \frac{\sigma_p^2}{4} + \frac{\sigma_e^2}{8}
$$

By comparison, under the recommended design, the pot-level random effect $p_{ij}$ and the tray effect $t_j$ cancel out in the contrast (difference), since both genotypes are observed within the same pots and trays. 

Making the variance under the recommended design: 

$$
\text{Var}(\bar{y}_{1\cdot\cdot} - \bar{y}_{2\cdot\cdot}) = \frac{\sigma_e^2}{8}
$$

This recommendation effectively eliminates additional sources of variation present in the original design, and as a result would provide more precise (and still unbiased) estimates of average genotype differences. 

Also, for what it's worth, I believe this sort of paired design was something R.A. Fisher wrote about when he was doing soil-plot experiments some time ago.

\newpage 

# Q2 

This is a continuation of Problem 1. Suppose the experiment actually involved a second factor—bacterial infection with levels 1=present and 2=absent—in addition to the factor genotype, randomly assigned to pots as discussed previously. Within each pot, one of the two plants was randomly selected for infection with a bacteria, which was applied by rubbing a gel containing the bacteria on the top leaf of the plant. The other plant in each pot was rubbed with the same gel but with the bacteria absent.

Let $y_{ijk}$ be the response for the plant of genotype $i$ on tray $j$ that received bacterial infection $k$ ($i=1,2; j=1,\ldots,8; k=1,2$). Suppose the data are the same as in Table 1 and arranged so that in each pot, Plant 1 corresponds to the plant infected with the bacteria and Plant 2 corresponds to the plant not infected with the bacteria. Suppose:

$$
y_{ijk} = \mu_{ik} + t_j + p_{ij} + e_{ijk} \quad \forall \; i, j, k,
$$

where, as in model (1), $t_j \sim \mathcal{N}(0, \sigma_t^2) \;\forall \; j$, $p_{ij} \sim \mathcal{N}(0, \sigma_p^2) \;\forall \; i, j$, $e_{ijk} \sim \mathcal{N}(0, \sigma_e^2) \;\forall \; i, j, k$, and all $t_j$, $p_{ij}$, and $e_{ijk}$ terms are mutually independent.

## a)

This is a split-plot experiment. What are the whole-plot experimental units?

### Answer

Pots 

## b)

What are the split-plot experimental units?

### Answer

Plants

## c)

What is the whole-plot treatment factor?

### Answer

Genotype

## d)

What is the split-plot treatment factor?

### Answer

Bacterial infection

## e)

Create an ANOVA table with columns Source and Degrees of Freedom.

### Answer

| Source                  | DF         | 
|-------------------------|------------|
| Trays                   | 7          |
| Genotypes               | 1          | 
| Trays $\times$ Genotypes | 7         |
| Infections              | 1          |
| Genotypes $\times$ Infections | 1    | 
| Error                   | 14         | 
| Corrected Total         | 31         | 

## f)

Give formulas for each of the Sums of Squares of the ANOVA table. (Shortcut formulas for degrees of freedom and sums of squares work in this case because of the balanced experimental design.)

### Answer

Copying the prior table and adding Sums of Squares: 

| Source                  | DF         | SS                                                                 |
|-------------------------|------------|--------------------------------------------------------------------|
| Trays                   | 7          | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (\bar{y}_{.j.} - \bar{y}_{...})^2$ |
| Genotypes               | 1          | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (\bar{y}_{i..} - \bar{y}_{...})^2$ |
| Trays $\times$ Genotypes | 7          | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (\bar{y}_{ij.} - \bar{y}_{i..} - \bar{y}_{.j.} + \bar{y}_{...})^2$ |
| Infections              | 1          | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (\bar{y}_{..k} - \bar{y}_{...})^2$ |
| Genotypes $\times$ Infections | 1 | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (\bar{y}_{i.k} - \bar{y}_{i..} - \bar{y}_{..k} + \bar{y}_{...})^2$ |
| Error                   | 14         | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (y_{ijk} - \bar{y}_{ij.} - \bar{y}_{i.k} + \bar{y}_{i..})^2$ |
| Corrected Total         | 31         | $\sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 (y_{ijk} - \bar{y}_{...})^2$ |

\newpage 

## g)

Derive the expected mean square for the second to last line of the ANOVA table (the line right before corrected total). This line is typically called error or split-plot error.

### Answer

To start, note: 

$$
E(MS_{\text{error}}) = \frac{1}{14} E(SS_{\text{error}})
$$

From the formula given in the ANOVA table above:

$$
E(MS_{\text{error}}) = \frac{1}{14} E \left\{ \sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 \left( y_{ijk} - \bar{y}_{ij.} + \bar{y}_{i.k} + \bar{y}_{i..} \right)^2 \right\}
$$

Using the model form:

$$
E(MS_{\text{error}}) = \frac{1}{14} E \left\{ \sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 \left[ (\mu_{ik} + t_j + p_{ij} + e_{ijk}) - (\bar{\mu}_{i.} + \bar{t} + \bar{p}_{i.} + \bar{e}_{ij.}) - (\bar{\mu}_{.k} + \bar{t} + \bar{p}_{.} + \bar{e}_{i.k}) + (\bar{\mu} + \bar{t} + \bar{p} + \bar{e}_{i..}) \right]^2 \right\}
$$

Cancelling appropriate terms, and noting independence assumptions:

$$
E(MS_{\text{error}}) = \frac{1}{14} E \left\{ \sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 \left( e_{ijk} - \bar{e}_{ij.} - \bar{e}_{i.k} + \bar{e}_{i..} \right)^2 \right\}
= \frac{1}{14} E \left\{ \sum_{i=1}^2 \sum_{j=1}^8 \sum_{k=1}^2 \left[ (e_{ijk} - \bar{e}_{ij.}) - (\bar{e}_{i.k} - \bar{e}_{i..}) \right]^2 \right\}
$$

Linearity of Expectation gives us:

$$
E(MS_{\text{error}}) = \frac{1}{14} \sum_{i=1}^2 \sum_{j=1}^8 E \left\{ \sum_{k=1}^2 \left[ (e_{ijk} - \bar{e}_{ij.}) - (\bar{e}_{i.k} - \bar{e}_{i..}) \right]^2 \right\}
$$

Now noting variance properties::

$$
E(MS_{\text{error}}) = \frac{1}{14} \sum_{i=1}^2 \sum_{j=1}^8 (2 - 1) \cdot \text{Var}(e_{ijk} - \bar{e}_{i.k})
$$

Expanding:

$$
E(MS_{\text{error}}) = \frac{1}{14} \sum_{i=1}^2 \sum_{j=1}^8 (2 - 1) \cdot \text{Var} \left( \frac{7}{8} e_{ijk} - \frac{1}{8} \sum_{j' \neq j} e_{ij'k} \right)
= \frac{1}{14} \cdot 2 \cdot 8 \cdot 1 \cdot \left[ \left( \frac{7}{8} \right)^2 + 7 \cdot \left( \frac{1}{8} \right)^2 \right] \sigma_e^2
$$

Giving us the desired: 

$$
E(MS_{\text{error}}) = \sigma_e^2
$$

## h)

Compute the value of the best linear unbiased estimator of $\mu_{11} - \mu_{12}$.

### Answer

$\bar{y}_{1.1} - \bar{y}_{1.2} = -1$

## i)

Derive an expression for the variance of the best linear unbiased estimator of $\mu_{11} - \mu_{12}$ in terms of model (2) parameters.

### Answer

$$
\widehat{\text{Var}({\mu_{11} - \mu_{12}})} = \frac{1}{4} \sigma_e^2
$$

\newpage 

## j)

Compute a 95% confidence interval for $\mu_{11} - \mu_{12}$.

Plus Interpretation! 

### Answer

```{r}
plant_data <- data.frame(
  Tray = rep(1:8, each = 4),
  Genotype = rep(c("G1", "G1", "G2", "G2"), times = 8),
  Plant = rep(c("Plant1", "Plant2"), times = 16),
  Value = c(
    8, 7, 6, 7,
    8, 9, 4, 5,
    8, 8, 7, 7,
    5, 7, 4, 2,
    5, 6, 4, 3,
    9, 10, 7, 9,
    5, 7, 1, 4,
    4, 6, 5, 5
  )
)

plant_data <- plant_data |>
  mutate(Infection = ifelse(Plant == "Plant1", "infected", "not_infected"))

means <- plant_data |>
  group_by(Genotype, Tray) |>
  mutate(y_ij_dot = mean(Value)) |>
  group_by(Genotype, Infection) |>
  mutate(y_i_k = mean(Value)) |>
  group_by(Genotype) |>
  mutate(y_i_dot_dot = mean(Value)) |>
  ungroup()

means <- means |>
  mutate(resid = Value - y_ij_dot - y_i_k + y_i_dot_dot,
         sq_resid = resid^2)

SS_error <- sum(means$sq_resid)
MS_error <- SS_error/14
varEst <- MS_error/4
varEst
```

```{r}
# est <- -plant_data_wide$d_j[1]
est <- mean(plant_data_wide$G1_P1) - mean(plant_data_wide$G1_P2)

varEst <- MS_error/4
moe <- qt(p = 0.975, df = 14)*(sqrt(varEst))
  
lb <- est - moe
ub <- est + moe

cat("Lower bound:", lb, "\nUpper bound:", ub, "\n")
```

$$
\widehat{\mu_{11} - \mu_{12}} \pm t_{0.975, 14} \cdot (\frac{1}{4}) \sigma_e^2 \rightarrow -1 \pm (2.1448 \cdot 0.4818) = (-2.0334, 0.0334)
$$

Interpretation: We are 95% confident that the true mean difference in overall plant health between infected and uninfected Genotype 1 plants (infected minus uninfected) is between -2.03 and 0.03, again using units of “plant health” where higher values indicate greater health. Because this interval includes zero, we do not have strong evidence to in support of bacterial infection having a statistically significant effect on the average plant health of Genotype 1, based on the linear model averaging over trays, pots, and plants, and accounting for random variability due to trays, pots, and residual error.

\newpage

## k)

Determine the distribution of $y_{111} - y_{112} - y_{211} + y_{212}$.

### Answer

We consider a linear combination of four normally distributed random variables. Under the model:

$$
y_{ijk} = \mu_{ik} + t_j + p_{ij} + e_{ijk},
$$

we have:

$$
\begin{aligned}
y_{111} &= \mu_{11} + t_1 + p_{11} + e_{111} \\
y_{112} &= \mu_{12} + t_1 + p_{11} + e_{112} \\
y_{211} &= \mu_{21} + t_1 + p_{21} + e_{211} \\
y_{212} &= \mu_{22} + t_1 + p_{21} + e_{212}
\end{aligned}
$$

So for the linear combination in question, we have:

$$
\begin{aligned}
y_{111} - y_{112} - y_{211} + y_{212}
&= (\mu_{11} - \mu_{12} - \mu_{21} + \mu_{22}) \\
&\quad + (t_1 - t_1 - t_1 + t_1) \\
&\quad + (p_{11} - p_{11} - p_{21} + p_{21}) \\
&\quad + (e_{111} - e_{112} - e_{211} + e_{212}) \\
&= (\mu_{11} - \mu_{12} - \mu_{21} + \mu_{22}) + (e_{111} - e_{112} - e_{211} + e_{212})
\end{aligned}
$$

Because the random effects $t_1$ and $p_{ij}$ cancel out, the distribution depends only on the independent residual errors.

Each $e_{ijk} \sim \mathcal{N}(0, \sigma_e^2)$, independently, so their linear combination has variance:

$$
\text{Var}(y_{111} - y_{112} - y_{211} + y_{212}) = \sigma_e^2 + \sigma_e^2 + \sigma_e^2 + \sigma_e^2 = 4\sigma_e^2
$$

Thus, the linear combination follows a normal distribution:

$$
y_{111} - y_{112} - y_{211} + y_{212} \sim \mathcal{N}(\mu_{11} - \mu_{12} - \mu_{21} + \mu_{22}, 4\sigma_e^2)
$$

\newpage 

## l)

Compute the value of the best linear unbiased estimator of $\mu_{11} - \mu_{12} - \mu_{21} + \mu_{22}$.

### Answer

```{r}
est <- mean(plant_data_wide$G1_P1) - mean(plant_data_wide$G1_P2) - mean(plant_data_wide$G2_P1) + mean(plant_data_wide$G2_P2)
est
```

$\bar{y}_{1.1} - \bar{y}_{1.2} - \bar{y}_{2.1} + \bar{y}_{2.2} = -0.5$.

## m)

Derive an expression for the variance of the best linear unbiased estimator of $\mu_{11} - \mu_{12} - \mu_{21} + \mu_{22}$ in terms of model (2) parameters.

### Answer

We have:

$$
\begin{aligned}
\text{Var}(\bar{y}_{1.1} - \bar{y}_{1.2} - \bar{y}_{2.1} + \bar{y}_{2.2})
&= \text{Var} \left( 
(\mu_{11} + \bar{t} + \bar{p}_1 + \bar{e}_{1.1}) 
- (\mu_{12} + \bar{t} + \bar{p}_1 + \bar{e}_{1.2}) \right. \\
&\quad \left.
- (\mu_{21} + \bar{t} + \bar{p}_2 + \bar{e}_{2.1}) 
+ (\mu_{22} + \bar{t} + \bar{p}_2 + \bar{e}_{2.2})
\right) \\
&= \text{Var}(\bar{e}_{1.1} - \bar{e}_{1.2} - \bar{e}_{2.1} + \bar{e}_{2.2})
\end{aligned}
$$

Giving us:

$$
\begin{aligned}
\text{Var}(\bar{e}_{1.1} - \bar{e}_{1.2} - \bar{e}_{2.1} + \bar{e}_{2.2})
&= 4 \cdot \frac{1}{2} \sigma_e^2 \\
&= \frac{4}{8} \sigma_e^2 \\
&= \frac{1}{2} \sigma_e^2
\end{aligned}
$$

\newpage 

# Q3

Researchers created a device to test the effectiveness of helmets at reducing the stress caused by head impacts. The device includes a head-shaped sensor on which a helmet can be placed, as well as a striking weight that can produce impacts to the front or side of a helmet placed on the sensor. The intensity of each impact can be controlled by the researchers. When an impact is delivered, a measurement of the amount of stress experienced by the head-shaped sensor is recorded. A measurement of 0 indicates no stress, while a measurement of 100 indicates stress high enough to cause serious brain injury.

The researchers used the device to test a total of 10 helmets consisting of 5 helmets of type 1 and 5 helmets of type 2. The 10 helmets were tested in random order. When each helmet was tested, it was struck a total of 4 times: once with low impact to the front, once with high impact to the front, once with low impact to the side, and once with high impact to the side. The order of the 4 impacts was determined separately for each helmet using the following procedure. A fair coin was flipped. If the result of the flip was heads, the first two impacts were front impacts and the last two impacts were side impacts. If the result of the flip was tails, the first two impacts were side impacts and the last two impacts were front impacts. For the first two impacts, the coin was flipped again. If the result of the flip was heads, the first impact was at low intensity and the second was at high intensity. If the result of the flip was tails, the first impact was at high intensity and the second at low intensity. A coin was flipped a third time to determine the order of the impact intensities for the third and fourth impacts so that each order (low and then high vs. high and then low) was equally likely.

Let $i=1,2$ index helmet types 1 and 2. Let $j=1,\ldots,5$ index helmets nested within helmet types. Let $k=1,2$ index the direction of impact, with $k=1$ for front and $k=2$ for side. Let $\ell=1,2$ index the intensity of the impact, with $\ell=1$ for low and $\ell=2$ for high. Let $y_{ijk\ell}$ be the stress measurement for the corresponding values of $i$, $j$, $k$, and $\ell$. For $i=1,2$, $j=1,\ldots,5$, $k=1,2$, and $\ell=1,2$, consider the model:

$$
y_{ijk\ell} = \mu_{ik\ell} + a_{ij} + b_{ijk} + e_{ijk\ell},
$$

where the $\mu_{ik\ell}$ values are unknown parameters, $a_{ij} \sim \mathcal{N}(0, \sigma_a^2)$, $b_{ijk} \sim \mathcal{N}(0, \sigma_b^2)$, $e_{ijk\ell} \sim \mathcal{N}(0, \sigma_e^2)$, and all random terms are independent. Model (3) was fit to the dataset, and the following ANOVA table was obtained. Because we have a balanced experimental design, the type I and type III sums of squares are the same, and the lines of the ANOVA table can be reordered in a variety of ways without changing the results.

| Source                             | Sum of Squares | Expected Mean Square                        |
|------------------------------------|----------------|---------------------------------------------|
| Type                               | 226            | —                                           |
| Direction                          | 255            | —                                           |
| Intensity                          | 8910           | —                                           |
| Type × Direction                   | 207            | —                                           |
| Type × Intensity                   | 2              | —                                           |
| Direction × Intensity             | 7              | —                                           |
| Type × Direction × Intensity      | 9              | —                                           |
| Helmet(Type)                       | 254            | $4\sigma_a^2 + 2\sigma_b^2 + \sigma_e^2$ |
| Direction × Helmet(Type)          | 114            | $2\sigma_b^2 + \sigma_e^2$               |
| Error                              | 59             | $\sigma_e^2$                             |
| Corrected Total                    | 10043          | —                                           |

\newpage 

## a)

We learned a shortcut for expressing sums of squares in summation notation that works for balanced designs like the one considered here. Use that shortcut to express the sum of squares for Direction $\times$ Intensity using summation notation.

### Answer

$$
(k - 1)(\ell - 1) = 4 - 2 - 2 + 1 = 1
$$

So, using the shortcut, we have:

$$
SS_{\text{Dir} \times \text{Int}} = \sum_{i=1}^2 \sum_{j=1}^5 \sum_{k=1}^2 \sum_{l=1}^2 (\bar{y}_{-kl} - \bar{y}_{-k} - \bar{y}_{-l} + \bar{y}_{...})^2
= 10 \sum_{k=1}^{2} \sum_{\ell=1}^{2} \left( \bar{y}_{\cdot\cdot k\ell} - \bar{y}_{\cdot\cdot k\cdot} - \bar{y}_{\cdot\cdot\cdot\ell} + \bar{y}_{\cdot\cdot\cdot\cdot} \right)^2
$$

## b)

Compute a t statistic that can be used to test $H_0: \bar{\mu}_{1\cdots} = \bar{\mu}_{2\cdots}$.

### Answer

This is a test of a whole-plot (helmet type) effect. The corresponding null hypothesis is:

$$
H_0: \bar{\mu}_{1\cdot \cdot} = \bar{\mu}_{2\cdot \cdot}
$$

Since helmet type is a whole-plot factor and helmets are nested within helmet type, the correct denominator for the test statistic comes from the mean square for `Helmet(Type)`. The test statistic for comparing two group means in a mixed model can be written in two equivalent ways:

As an F-test:

$$
F_{1,8} = \frac{MS_{\text{Type}}}{MS_{\text{Helmet(Type)}}} = \frac{226 / 1}{254 / 8} = \frac{226}{31.75} \approx 7.12,
$$

or equivalently, as a t-test:

$$
t_8 = \sqrt{ \frac{MS_{\text{Type}}}{MS_{\text{Helmet(Type)}}} } = \sqrt{ \frac{226}{31.75} } \approx \sqrt{7.12} \approx 2.67.
$$

This t-statistic follows a $t$-distribution with 8 degrees of freedom, corresponding to the degrees of freedom associated with the `Helmet(Type)` error term (i.e., 10 helmets (5 of each type) – 2 types = 8). This test assesses whether the average stress differs between helmet types.

\newpage

## c)

The statistic in part b) has a noncentral t distribution. Provide an expression for the noncentrality parameter in terms of model (3) parameters.

### Answer

From part b), we are testing the difference between the type means:

$$
H_0: \bar{\mu}_{1\cdots} = \bar{\mu}_{2\cdots}
$$

Since we have a balanced design, the BLUE of $\mu_{1\cdots} - \mu_{2\cdots}$ is:

$$
\bar{y}_{1\cdots} - \bar{y}_{2\cdots}
$$

Which is normally distributed with:

Mean: $E(\bar{y}_{1\cdots} - \bar{y}_{2\cdots}) = \mu_{1\cdots} - \mu_{2\cdots}$

And variance:

$$
\begin{aligned}
\text{Var}(\bar{y}_{1\cdots} - \bar{y}_{2\cdots}) 
&= \text{Var}(a_{1.} - a_{2.} + b_{1..} - b_{2..} + e_{1...} - e_{2...}) \\
&= \text{Var}(a_{1.} - a_{2.}) + \text{Var}(b_{1..} - b_{2..}) + \text{Var}(e_{1...} - e_{2...}) \\
&= \frac{2\sigma_a^2}{5} + \frac{2\sigma_b^2}{10} + \frac{2\sigma_e^2}{20} \\
&= \frac{1}{10} (4\sigma_a^2 + 2\sigma_b^2 + \sigma_e^2) \\
&= \frac{1}{10} E\left\{ MS_{\text{Helmet(Type)}} \right\}
\end{aligned}
$$

Taken together, the ncp, $\delta$ for the t-statistic in part b) is:

$$
\delta = \frac{\mu_{1\cdots} - \mu_{2\cdots}}{\sqrt{(4\sigma_a^2 + 2\sigma_b^2 + \sigma_e^2)/10}}
$$

This ncp is assumed to be 0 under the null and $\delta$ under the alternative hypothesis. 

\newpage

## d)

Compute the value of an unbiased estimator for $\sigma_a^2$.

### Answer

To estimate the variance component $\sigma_a^2$, we need to use the expected mean squares from the ANOVA decomposition.

From the model, we know (and again, under a balanced design):

$E(MS_{\text{Helmet(Type)}}) = 4\sigma_a^2 + 2\sigma_b^2 + \sigma_e^2$

$E(MS_{\text{Direction} \times \text{Helmet(Type)}}) = 2\sigma_b^2 + \sigma_e^2$

Subtracting these expressions eliminates the subplot-level variance terms:

$$
E(MS_{\text{Helmet(Type)}} - MS_{\text{Direction} \times \text{Helmet(Type)}}) = 4\sigma_a^2
$$

Thus, an unbiased estimator of $\sigma_a^2$ is:

$$
\hat{\sigma}_a^2 = \frac{MS_{\text{Helmet(Type)}} - MS_{\text{Dir} \times \text{Helmet(Type)}}}{4}
= \frac{254/8 - 114/8}{4}
= \frac{140}{32}
= 4.375
$$

## e)

The best linear unbiased estimator of $\bar{\mu}_{12\cdot} - \bar{\mu}_{11\cdot}$ is equal to 0.5 for this dataset. Provide a 95% confidence interval for $\bar{\mu}_{12\cdot} - \bar{\mu}_{11\cdot}$.

Plus Interpretation! 

### Answer

We are given that the BLUE of $\bar{\mu}_{12\cdots} - \bar{\mu}_{11\cdots}$ is:

$$
\bar{y}_{1\cdot2\cdot} - \bar{y}_{1\cdot1\cdot} = 0.5
$$

To form a confidence interval we need the estimated variance of $\bar{\mu}_{12\cdots} - \bar{\mu}_{11\cdots}$ as well. 

Since the comparison is within helmet type, the appropriate error term is the subplot error, which includes variation due to `Direction × Helmet(Type)` and the residual error.

Referring back to the model specification:

$$
\text{Var}(\bar{y}_{1\cdot2\cdot} - \bar{y}_{1\cdot1\cdot}) = \frac{1}{5} \left(2\sigma_b^2 + \sigma_e^2\right)
= \frac{1}{5} \left( \frac{114}{8} \right) = \frac{1}{5} (14.25) = 2.85
$$

```{r}
tval <- qt(p = 0.975, df = 8)
tval
```

We use $t_{0.975,8} = 2.306$, based on the 8 degrees of freedom associated with `Direction × Helmet(Type)`.

Combining all the information together then, the 95% confidence interval is:

$$
0.5 \pm 2.306 \cdot \sqrt{2.85} \approx 0.5 \pm 3.89
\rightarrow (-3.39,\ 4.39)
$$

Interpretation: We are 95% confident that the true mean difference in stress impact between side and front impacts for Type 1 helmets (side minus front) is between –3.39 and 4.30, using units of “stress” where higher values indicate greater stress on a helmet for a user. Because this confidence interval includes zero, we do not have evidence in support of there being an average difference in the stress of impact between helmets of Type 1 when impacted by the front or by the side, based on the linear model averaging over helmets and impact intensity, and accounting for random variability due to helmets, helmet-direction interactions, and residual error.

## f)

Compute a standard error for the best linear unbiased estimator of $\mu_{121} - \mu_{111}$.

### Answer

We are estimating the standard error for the difference between high and low intensity impacts in the front direction for type 1 helmets. This is a particular within helmet comparison, so it is derived from subplot-level variation only. 

From the model, the variance of this contrast is given by:

$$
\text{Var}(\bar{y}_{1\cdot21} - \bar{y}_{1\cdot11}) = \frac{2}{5} \left( \sigma_b^2 + \sigma_e^2 \right)
$$

Substituting known values of the mean squares, we have:

$MS_{\text{Direction} \times \text{Helmet(Type)}} = \frac{114}{8} = 14.25$

And: 

$MS_{\text{Error}} = \frac{59}{16} = 3.6875$

Taken together: 

$$
\hat{\text{Var}} = \frac{2}{5} \left( \frac{14.25 + 3.6875}{2} \right) = \frac{2}{5} \cdot 8.96875 = 3.5875
$$

Giving us: 

$$
SE = \sqrt{3.5875} \approx 1.894
$$