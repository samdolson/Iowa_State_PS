---
output:
  pdf_document: default
  html_document: default
---

# HW 2 
[Name: Sam Olson]{.smallcaps} \
[Collaborators: XXX]{.smallcaps} \

## Progress Report 
  - 1:  
  - 2: 
  - 3: DONE
  - 4: 
  - 5: 
  - 6: 
  - 7: 
  - 8: 

>> # Fig. 1
Used in Q7, part (b)

\[
1 = \int\limits_{\infty}^{\infty}{\frac{1}{\sqrt{2\pi}}x^2 e^{\frac{-x^2}{2}}dx} = \frac{2}{\sqrt{2\pi}}\int\limits_{0}^{\infty}{x^2 e^{\frac{-x^2}{2}}dx}
\]

# 1. 
>> Q: Suppose a random variable X has the following cdf from class (which is neither a step function nor continuous):  

\[
F(x) = 
\begin{cases}
  1 & x < 0 \\
  1 & 0 \leq x \leq 1 \\ 
  0 & x > 1
\end{cases}
\]

(a): Find the following probabilities: 
  $P(X > \frac{1}{2})$
  $P(X \geq \frac{1}{2})$
  $P(0 < X \leq \frac{1}{2})$
  $P(0 \leq X \leq \frac{1}{2})$

(b): Conditional on the event "X > 0", the corresponding conditional pdf of X (i.e. given X > 0) is as follows at $x \in \mathbb{R}$: 

\[
P(X \leq x | X > 0 ) = \frac{P(X \leq x , X > 0 )}{P(X > 0)} = \frac{P(0 < X \leq x)}{P(X > 0)} = \frac{F(x) - F(0)}{1 - F(0)}
\]

Giving: 

\[
P(X \leq x | X > 0 ) = 
\begin{cases}
  0 & x \leq 0 \\
  x & 0 < x \leq 1 \\ 
  1 & x > 1
\end{cases}
\]

Based on the conditional cdf above, show that the distribution of X, conditional on "X > 0", is the same (i.e. has the same cdf) as that of a random variable Y which is "uniform" on the interval (0, 1), having constant pdf $f_Y(y) = 1$ for $0 < y < 1$ (with $f_Y(y) = 0$ for all other $y \in \mathbb{R}$)

>> A: 

(a):

(b): 

\newpage

# 2. 
>> Q: Statistical reliability involves studying the time to failure of manufactured units. In many reliability textbooks, one can find the exponential distribution: 

\[
f(x) = 
\begin{cases}
  \frac{1}{\theta} e^{-\frac{x}{\theta}} & x > 0 \\
  0 & x \leq 0
\end{cases}
\]

where $\theta > 0$ is a fixed value, for modeling the time X that a random unit runs until failure (i.e. X is a survival time). Show that if X has an exponential distribution as above, then: 

$P(X > s + t | X > t) = P(X > s)$

for any values t, s > 0; this feature is called the "memoryless" property of te exponential distribution. 

>> A: 

\newpage

# 3. 2.3: 
>> Q: Suppose X has the Geometrc pmf: 

$f_X(x) = \frac{1}{3}(\frac{2}{3})^x$, $x = 0, 1, 2, ...$
Determine the probability distribution of $Y = \frac{X}{X+1}$
Note that here X and Y are discrete random variables. To specify the probability distribution of Y, specify its pmf. 

>> A: 

$f_Y(y) = P(Y = y) = P(\frac{X}{X+1} = y)$

Using this relation we have: 
$y(X+1) = X \rightarrow yX + y = X \rightarrow y = X - yX \rightarrow y = X(1-y)$

Thus we have: 
$X = \frac{y}{1-y}$

Returning then to the original function for the pmf, we have: 

$f_Y(y) = P(X = \frac{y}{1-y}) = \frac{1}{3}(\frac{2}{3})^\frac{y}{1-y}$

We must then identify the support of Y given $x = 0, 1, 2, ...$

For the support of X as given, $x = 0, 1, 2, ... \rightarrow y = \frac{X}{X+1} = \frac{0}{1}, \frac{1}{2}, \frac{2}{3}, ...$

Thus we define the discrete random variable Y by its pmf and support respectively as: 

$f_y(y) = \frac{1}{3}(\frac{2}{3})^\frac{y}{1-y}$ for $y = 0, \frac{1}{2}, \frac{2}{3}, ...$

\newpage

# 4. 2.4: 
>> Q: 

Let $\lambda$ be a fixed positive constant, and define the function $f(x)$ by: 

$f(x) = \frac{1}{2}\lambda e^{-\lambda x}$ if $x \geq 0$ 
and $f(x) = \frac{1}{2}\lambda e^{\lambda x}$ if $x < 0$

(a): Verify that $f(x)$ is a pdf. 

(b): If X is a random variable with pdf given by $f(X)$, find $P(X < t)$ $\forall t$. Evaluate all integrals.

(c): Find $P(|X| < t)$ $\forall t$. Evaluate all integrals. 

>> A: 

(a): 
(1): $f(x)$ is a pdf so long as it is well defined, i.e. $f(x) \geq 0$ $\forall x \in \mathbb{X}$ 
(2): and so long as 
$\int\limits_{x \in \mathbb{X}}{f(x)dx} = 1$

Then $f(x)$ is a (proper) pdf

(1): $f(x)$ is well-defined, i.e. ever negative.  

For $x \geq 0$, $e^{-x} \geq 0$, so by including additional, fixed (positive!) constants such as $\lambda$, $f(x) \geq 0$ for $x \geq 0$. 

For $x < 0$, $f(x) = e^{\lambda x} \geq 0$, so by including additional, fixed positive constants such as $\lambda$, $f(x) \geq 0$ for $x < 0$

Taken collectively, $f(x) \geq 0$ for all $x \in \mathbb{X}$

(2):
$$\int\limits_{x \in \mathbb{X}}{f(x)dx} = \int\limits_{x < 0}{\frac{1}{2}\lambda e^{\lambda x}} + \int\limits_{x \geq 0}{\frac{1}{2}\lambda e^{-\lambda x}}$$ 

$$\int\limits_{x \in \mathbb{X}}{f(x)dx} = \int\limits_{-\infty}^{0}{\frac{1}{2}\lambda e^{\lambda x}} + \int\limits_{0}^{\infty}{\frac{1}{2}\lambda e^{-\lambda x}}$$

Note, we can factor out a constant term from both integrals, giving us: 

$$\int\limits_{x \in \mathbb{X}}{f(x)dx} = \frac{1}{2}\lambda(\int\limits_{-\infty}^{0}{e^{\lambda x}} + \int\limits_{0}^{\infty}{e^{-\lambda x}}) = \frac{1}{2}\lambda [\frac{e^{\lambda x}}{\lambda}\big|_{-\infty}^{0} + (-\frac{e^{-\lambda x}}{\lambda}\big|_{0}^{\infty})]$$

$$\int\limits_{x \in \mathbb{X}}{f(x)dx} = \frac{1}{2}\lambda(\frac{1}{\lambda} - (-\frac{1}{\lambda})) = \frac{1}{2}\lambda (\frac{2}{\lambda}) = 1$$

We may then conclude that $f(x)$ is a (proper) pdf. 

(b):

(c):

\newpage

# 5. 2.6 (b, c): 
>> Q: In each of the following find the pdf of Y. (Do not need to verify the pdf/evaluate the integration, per Instructions).  

(b): $f_X(x) = \frac{3}{8}(x + 1)^2$, $-1 < x < 1$; $Y = 1 - X^2$

(c): $f_X(x) = \frac{3}{8}(x + 1)^2$, $-1 < x < 1$; $Y = 1 - X^2$ if $X \leq 0$ and $Y = 1 - X$ if $X > 0$

>> A: 

(b): 

(c): 

\newpage

# 6. 2.9: 
>> Q: If the random variable X has pdf: 
\[
f(x) = 
\begin{cases}
  \frac{x-1}{2} & 1 < x < 3 \\
  0 & \text{otherwise}
\end{cases}
\]

find a monotone function $u(x)$ such that the random variable $Y = u(X)$ has a Uniform(0,1) distribution.

>> A: 

\newpage

# 7. 2.22 (a, b): 
>> Q: Let X have the pdf: 

$f(x) = \frac{4}{\beta^3\sqrt{\pi}}x^2e^{\frac{-x^2}{\beta^2}}$, $0 < x < \infty$, $\beta>0$

(a): Verify that $f(x)$ is a pdf.  

(b): Find $E(X)$

>> A:

(a):

(b): 

\newpage

# 8. 
>> Q: Suppose that a random variable U has a Uniform(0,1) distribution 

(i.e. pdf $f_U(u) = 1$ for 0 < u < 1)

(a): Suppose a random variable Xhas a cdf $F(x)$ which is strictly increasing and continuous on $x \in \mathbb{R}$; this implies that, for any real value of 0 < u < 1, there is an inverse $F^{-1}(u) = x \in \mathbb{R}$ so that $F(x) = F(F^{-1}(u)) = u$. Define a random variable $Y = F^{-1}(U)$ based on the random variable U. Show that X and Y have the same cdf (i.e. the same distributions).

Hint: Use that, because F is strictly increasing, $P(Y \leq y) = P(F(Y) \leq F(y))$ holds for any $y \in \mathbb{R}$, i.e., Y can be less than or equal to y if and only if F(Y) is less than or equal to $F(y)$. Noe that $F(y) \in (0, 1)$ for any real y. 

(b): If there is a computer program (i.e. random number generator) that produces numbers uniformly distributed between zero and one (i.e., according to the pdf $F_U(u)$), explain how these numbers could be  used to generate values distributed according to the pdf $f_Z(z) = \frac{e^{-|z|}}{2}$, $-\infty < z < \infty$. 

Hint: Use (a) where F now becomes the cdf of Z; you need to find $F^{-1}(u)$ for a given 0 < u < 1 by solving the expression $F(z) = u$ for $z \in \mathbb{R}$

>> A: 

(a): 

(b): 
