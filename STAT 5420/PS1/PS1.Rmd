---
title: "HW1"
output:
  pdf_document: default
  html_document: default
author: "Sam Olson"
---

> 1. 1.12 It was noted in Section 1.2.1 that statisticans who follow the deFinetti school do not accept the Axiom of Countable Additivity, instead adhering to the Axiom of Finite Additivity. 

(a) 

Show that the Axiom of Countable Additivity implies Finite Additivity. 

(1) Definition of Axiom of Countable Additivity: 

If $A_1, A_2, ... \in \mathbb{B}$ are pairwise disjoint, then 

$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = \sum\limits_{i=1}^{\infty}{P(A_i)}$

(2) Goal: 

We wish to prove that: 

$P(\bigcup\limits_{i=1}^{n}{B_i}) = \sum\limits_{i=1}^{n}{P(B_i)}$

For $B_1, B_2, ..., B_n$ pairwise disjoint. 

(3) Method: 

Define an infinite sequence of disjoint events, $A_1, A_2, ...$ as pairwise disjoint sets.  
and let us also define a finite sequence of disjoint events, $B_1, B_2, ..., B_n$. 

Furthermore, let: 
$(\bigcup\limits_{i=1}^{\infty}{A_i}) = (\bigcup\limits_{i=1}^{n}{B_i})$, meaning the sets of $A_i \text{ where } A_i \neq B_i \text{ are empty sets}$

We may write their associated probabilities as: 
$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = P(\bigcup\limits_{i=1}^{n}{B_i})$

And define: $\forall i \in [1, n]$, $A_i = B_i$ and $\forall i \notin [1,n]$, $A_i = \emptyset$

Then, as: 

$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = P(\bigcup\limits_{i=1}^{n}{B_i}) + P(\bigcup\limits_{i=n+1}^{\infty}{A_i})$

$$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = P(\bigcup\limits_{i=1}^{n}{A_i} \bigcup\limits_{i=n+1}^{\infty}{A_i} = P(\bigcup\limits_{i=1}^{n}{B_i} \bigcup\limits_{i=n+1}^{\infty}{\emptyset} = P(\bigcup\limits_{i=1}^{n}{B_i}) + P(\bigcup\limits_{i=n+1}^{\infty}\emptyset)$$

$$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = P(\bigcup\limits_{i=1}^{n}{B_i}) + P(\bigcup\limits_{i=n+1}^{\infty}\emptyset) = P(\bigcup\limits_{i=1}^{n}{B_i}) + \emptyset = P(\bigcup\limits_{i=1}^{n}{B_i})$$
$$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = P(\bigcup\limits_{i=1}^{n}{B_i})$$

For the summation-side of the equation, we have: 

$\sum\limits_{i=1}^{\infty}{P(A_i)} = \sum\limits_{i=1}^{n}{P(A_i)} + \sum\limits_{i=n+1}^{\infty}{P(A_i)}  = \sum\limits_{i=1}^{n}{P(B_i)} + \sum\limits_{i=n+1}^{\infty}{P(A_i)} = \sum\limits_{i=1}^{n}{P(B_i)} + \sum\limits_{i=n+1}^{\infty} \emptyset$

Giving us: 

$\sum\limits_{i=1}^{\infty}{P(A_i)} = \sum\limits_{i=1}^{n}{P(B_i)} + \emptyset = \sum\limits_{i=1}^{n}{P(B_i)}$

We take advantage of the fact that: 

$P(\bigcup\limits_{i=1}^{\infty}{A_i}) = \sum\limits_{i=1}^{\infty}{P(A_i)}$

Allowing us to conclude: 

$P(\bigcup\limits_{i=1}^{n}{B_i}) = \sum\limits_{i=1}^{n}{P(B_i)}$.//

\newpage 

> 2. 1.13: If $P(A) = \frac{1}{3}$ and $P(B^{c}) = \frac{1}{4}$, can A and B be disjoint?

A: 

$P(A) = \frac{1}{3} \rightarrow P(A^{c}) = 1 - \frac{1}{3} = \frac{2}{3}$
and
$P(B^{c}) = \frac{1}{4} \rightarrow P(B) = 1 - \frac{1}{4} = \frac{3}{4}$

Let us consider $P(A) + P(B) = \frac{1}{3} + \frac{3}{4} = \frac{4}{12} + \frac{9}{12} = \frac{13}{12}$  

For two events to be disjoint, then $P(A \cap B) = 0$, or they cannot occur jointly. Furthermore, the following condition must hold: 

$P(A \cup B) = P(A) + P(B)$

However, as shown, $P(A) + P(B) = \frac{13}{12} > 1$

However, the probability over the sample space of all possible events must be at most 1 (between 0 and 1). Thus, if we assume events A and B are disjoint, we arrive at a contradiction.//

> 3. 

Suppose a family has 4 children, named a, b, c and d, who take turns washing 4 plates denoted $p_1, p_2, p_3, p_4$. These children are not so careful in their work, so, over time, each of the plates will be broken. Suppose any child could break any plate and that the ways in which plates $p_1, p_2, p_3, p_4$ could be broken by children a, b, c, d are equally likely. 

We may frame this problem as a problem of urns and balls, where each child is an urn and each broken plate is a ball. 
So, framing these problems as such, (a) is the probability that 3 balls are put into one particular urn, and (b) is the probability that 3 balls are put into any one urn.

With this framework, we have the following relevant calculations for (a) and (b): 

(1): $4\choose{3}$, the number of events where one particular child breaks 3 plates. 
(2): $4\choose{1}$, the number of events where one particular child breaks 1 plate. 
(3): $\frac{1}{4}$, the probability that one particular child breaks a plate
(4): $\frac{3}{4}$, the probability that one particular child does not break a plate.

(a) Find the probability that child a breaks 3 plates. 

We have (1), (3), and (4) from the above. 

Because we are looking at the probability that a particular child (child a) breaks 3 plates we have: 

$P(\text{child a breaks 3 plates}) = {{4}\choose{1}} (\frac{1}{4})^3 (\frac{3}{4})^1 = 4(\frac{1}{64})(\frac{3}{4}) = \frac{3}{64}$

(b) Find the probability that one of the four children breaks 3 plates. 

We have (1), (2), (3), and (4) from the above. 

Because we are looking at the probability that any particular child breaks 3 plates, we have exactly 4 possible scenarios from part (a), or said differently we multiple the probability of part (a) by 4. 

$P(\text{child a breaks 3 plates}) = 4{{4}\choose{1}} (\frac{1}{4})^3 (\frac{3}{4})^1 = 16(\frac{1}{64})(\frac{3}{4}) = \frac{1}{4}(\frac{3}{4}) = \frac{3}{16}$

\newpage 

> 4. 1.34 

Two litters of a particular rodent species have been born, one with two brown-haired and one gray-haired (litter 1), and the other with three brown-haired and two gray-haired (litter 2). We select a litter at random and then select an  offspring at random from the selected litter. 

(a) What is the probability that the animal chosen is brown-haired? 

$P(\text{brown-haired}) = P(\text{brown-haired} | \text{litter 1})P(\text{litter1}) + P(\text{brown-haired} | \text{litter 2}) P(\text{litter 2})$

$P(\text{brown-haired}) = (\frac{2}{3})\frac{1}{2} + (\frac{3}{5})\frac{1}{2}$

$P(\text{brown-haired}) = \frac{2}{6} + \frac{3}{10} = \frac{10}{30} + \frac{9}{30}$

$P(\text{brown-haired}) = \frac{19}{30}$

(b) Give that a brown-haired offspring was selected, what is the probability that the sampling was from litter 1? 

$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

where $P(A) = P(\text{litter 1}) = \frac{1}{2}$, 
$P(B) = P(\text{brown-haired}) = \frac{19}{30}$, and 
$P(B|A) = P(\text{brown-haired} | \text{litter 1}) = \frac{2}{3}$

$P(\text{litter 1} | \text{brown-haired}) = \frac{\frac{2}{3}\frac{1}{2}}{\frac{19}{30}}$

$P(\text{litter 1} | \text{brown-haired}) = \frac{\frac{2}{6}}{\frac{19}{30}}$

$P(\text{litter 1} | \text{brown-haired}) = \frac{1}{3} * \frac{30}{19}$

$P(\text{litter 1} | \text{brown-haired}) = \frac{10}{19}$

\newpage 

> 5. 1.38 

Prove each of the following statements. (Assume that any conditioning event has positive probability.)

(a) If $P(B) = 1$, then $P(A|B) = P(A)$ for any A. 

$P(B) = 1 \rightarrow P(B^{c}) = 1 - 1 = 0$

By definition: 
$P(A|B) = \frac{P(A \cap B)}{P(B)}$

So we find $P(A \cap B)$ through: 
$P (A \cap B^{c}) = P(A) - P(A \cap B)$,
$P(A \cap B) = P(A) - P (A \cap B^{c})$.

However, as $P(B^{c}) = 0$, 
$P(A \cap B) = P(A) - 0 = P(A)$

Giving us: 

$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)}{P(B)} = \frac{P(A)}{1}$

Thus, for $P(B) = 1$, $P(A|B) = P(A)$.//

(b) If $A \subset B$, then $P(B|A) = 1$ and $P(A|B) = \frac{P(A)}{P(B)}$

By definition: 
$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

Thus for $P(B|A) = 1$, we have: 

$P(A|B) = \frac{1*P(A)}{P(B)} = \frac{P(A)}{P(B)}$.//

(c) If A and B are mutually exclusive, then: 

$P(A | A  \cup B) = \frac{P(A)}{P(A) + P(B)}$

If A and B are mutually exclusive, then: 

$P(A \cup B) = P(A) + P(B)$

and $P(A \cap B) = 0$

So using the formula for conditional probability we have: 

$P(A|B) = \frac{P(A\cap B)}{P(B)} \rightarrow P(A | A \cup B) = \frac{P(A \cup (A \cap B))}{P(A \cup B)}$

Using Distributive Laws so have: 

$P(A \cup (A \cap B)) = P(A \cup A) \cap P(A \cup B) = P(A) \cap P(A \cup B) = P(A)$

So we have: 

$P(A | A \cup B) = \frac{P(A)}{P(A) + P(B)}$.//

(d) $P(A \cap B \cap C) = P(A | B \cup C) P(B | C)P(C)$

Base Formula: $P(A|B) = \frac{P(A\cap B)}{P(B)} \rightarrow P(A|B)P(B) = P(A \cap B)$

$P(A \cap B \cap C) = P(A \cap (B \cap C))$  

$P(A \cap B \cap C) = P(A|B \cap C)P(B \cap C)$ 

$P(A \cap B \cap C) = P(A | B \cap C)(P(B | C)P(C))$.//

\newpage 

> 6. 1.39 

A pair of events A and B cannot be simultaneously mutually exclusive and independent. Prove that $P(A) > 0$ and $P(B) > 0$ then: 

(1) If events A and B are mutually exclusive, then: $P(A \cap B) = 0$

(2) If events A and B are independent, then: $P(A | B) = P(A)$

(a) 

If A and B are mutually exclusive, they cannot be independent. 

Let A and B be mutually exclusive events. 

Let us then assume A and be are independent and $P(A) > 0$ and $P(B) > 0$. 

By their mutual exclusivity, (1) $P(A \cap B) = 0$
Let us then consider 
$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{0}{P(B)} = 0$
This implies that $P(A|B) = 0$, 
However, due to independence, $P(A|B) = P(A) > 0$. 

We thus have a contradiction via our assumption of independence.// 

(b)

If A and B are independent, they cannot be mutually exclusive. 

Let A and B now be independent events.

Furthermore define $P(A) > 0$ and $P(B) > 0$ and assume A and B are mutually exclusive. 

By independence (2), $P(A|B) = P(A)$ and $P(A \cap B) = P(A) P(B)$. 

However, by presuming mutual exclusivity (1), we have 

$P(A \cap B) = 0 \rightarrow P(A)P(B) = 0$

However, this requires $P(A), P(B)$, or both to be zero! 
Thus we're reached a contradiction from our presumption of mutual exclusivity.// 

\newpage 

> 7. 1.47 Prove that the following functions are cdfs. 

To prove a function is a (valid, proper) cdf, for our purposes we must verify: 

(1): $\lim_{x \rightarrow -\infty}{F(x) = 0}$
(2): $\lim_{x \rightarrow \infty} F(x) = 1$
(3): $F(x)$ is a nondecreasing function of x, i.e. $\frac{d}{dx}F(x) > 0$

>> 1.47 (c)

$F_{X}(x) = e^{-e^{-x}}$ for $x \in (-\infty, \infty)$

(1): $\lim_{x \rightarrow -\infty}{F(x)} = \lim_{x \rightarrow -\infty} e^{-e^{-x}} = e^{-\infty} = 0$
Note: $e^{-\infty} = \frac{1}{e^{\infty}} = \frac{1}{\infty} = 0$

So we conclude that $\lim_{x \rightarrow -\infty}{F(x)} = 0$

(2): $\lim_{x \rightarrow \infty}{F(x)} =  e^{-e^{-x}} = e^{0} = 1$

So we conclude that $\lim_{x \rightarrow \infty}{F(x)} = 1$

(3): $\frac{d(e^{-e^{-x}})}{dx}= e^{-x - e^{-x}}$
Note: For $x \in (-\infty, \infty)$, $e^{-x - e^{-x}} > 0$, 
So we conclude: $\frac{d}{dx}F(x) > 0$

(1), (2), and (3) are thus satisfied.//

>> 1.47 (d) 

$F_{X}(x) = 1 - e^{-x}$ for $x \in (0, \infty)$

(1): For, $x \in (0, \infty)$, 
$\lim_{x \rightarrow -\infty}{F(x)} = \lim_{x \rightarrow 0}{F(x)} = \lim_{x \rightarrow 0} {1 - e^{-x}} = \lim_{x \rightarrow 0} 1 - \frac{1}{e^x} = 1 - 1 = 0$

So we conclude that $\lim_{x \rightarrow -\infty}{F(x)} = 0$

(2): $\lim_{x \rightarrow \infty} = \lim_{x \rightarrow -\infty} {1 - e^{-x}} = 1 - 0$

So we conclude that $\lim_{x \rightarrow \infty}{F(x)} = 1$

(3): $\frac{d(1 - e^{-x})}{dx}= 0 - (-e^{-x}) = e^{-x}$
Note: For $x \in (0, \infty)$, $e^{-x} > 0$ so this condition is satisfied. 

So we conclude $\frac{d}{dx}F(x) > 0$

(1), (2), and (3) are thus satisfied.//

\newpage 

> 8. 1.54 

For each of the following, determine the value of c that makes $f(x)$ a pdf. 

To prove a function is a (valid, proper) pdf (for the continuous cases) we must verify: 

(1): $f_{X}(x) \geq 0$ for all x. 

(2): $\int\limits_{-\infty}^{\infty}{f_{X}(x)dx = 1}$

For all of the questions below, we know $f_{X}(x) \geq 0$ for all x in the support of X. 

>> (a)

(1): $f(x) = c * sin(x) \rightarrow 0  \leq f(x) \leq c(1)$ for $0 < x < \frac{\pi}{2}$

(2): 

$f(x) = c * sin(x)$ for $0 < x < \frac{\pi}{2}$

$\int c*sin(x) dx = c \int sin(x) dx = c (-cos(x))$

So evaluating over the range we have: 

$\int\limits_{0}^{\frac{\pi}{2}} c*sin(x) dx = c * (-cos(x)\big|_{0}^{\frac{\pi}{2}})$

$\int\limits_{0}^{\frac{\pi}{2}} c*sin(x) dx = c(-cos(\frac{\pi}{2}) + cos(0)) = c (1) = c$

So for the integral to evaluate to 1 over the support, we have 

$c = 1$

>> (b) 

(1): $f(x) = c*e^{-|x|} \rightarrow  0 \leq f(x) \leq c(1)$ for $-\infty < x < \infty$

(2): 

$f(x) = c*e^{-|x|}$ for $-\infty < x < \infty$

As the absolute value does not have a defined derivative, we must separate $f(x)$ into two distinct integrals. 

$\int\limits_{-\infty}^{\infty}{e^{-|x|}} = \int\limits_{-\infty}^{0}{e^{x}}  + \int\limits_{0}^{\infty}{e^{-x}}$

So we have: 

(a): $\int e^x dx = e^{x}$

(b): $\int e^-x dx = -e^{-x}$

Over the respective range of x values, we may evaluate: 

(a): $\int\limits_{-\infty}^{0}{e^{x}} = e^{x} \big|_{-\infty}^{0} = 1 - 0 = 1$

(b): $\int\limits_{0}^{\infty}{e^{-x}} = -e^{-x}\big|_{0}^{\infty} = 0 - (-1) = 1$

Combining (a) and (b) we have: 

$\int\limits_{-\infty}^{\infty}{e^{-|x|}} = 1 + 1 = 2$

So if we include the constant c (which can be factored out of the integral), we have: 

$\int\limits_{-\infty}^{\infty}c * {e^{-|x|}} = c * \int\limits_{-\infty}^{\infty} {e^{-|x|}}  = c(1 + 1) = c(2)$

To have this evaluate to 1, we must set $c = \frac{1}{2}$

\newpage 

> 9. 

From the axioms of probability, it follows that probability functions $P(\cdot)$ exhibit "monotone continuity from above (mcfa)" (which you don't have to worry about showing), meaning that for any decreasing sequence of sets/events  

$A_1 \supset A_2 \supset A_3 \supset \space ...$, 

$$\lim_{n \rightarrow \infty}{P(A_n)} = P(\bigcap\limits_{i=1}^{\infty}A_i)$$

By using/applying the mcfa property, show that the cdf $F$ of a random variable $X$ must be right continuous for any $x \in \mathbb{R}$, 

$\lim_{n \rightarrow \infty}{F(x + n^{-1})} = F(x)$

holds. 

>> A: 

Objective: Given the mcfa property, we wish to prove the cdf $F$ of a random variable $X$ must be right continuous, $\forall x \in \mathbb{R}$, the following holds: 

$$\forall x \in \mathbb{R}, \text{ } lim_{n \rightarrow \infty} {F(x + n^{-1})} = F(x)$$


Proof: 
Let us start by defining terms: 

We have a cdf $F$ or a random variable $X$, which we assume to exhibit "monotone continuity from above (mcfa)". 

We may define a decreasing sequence of sets/events $A_1 \supset A_2 \supset \text{ ...}$ such that: 

$$\lim_{n \rightarrow \infty}{P(A_n)} = P(\bigcap\limits_{i=1}^{\infty}A_i)$$

Define the sequence of sets, $A_n = \{ X \leq x + n^{-1}\}$, and note this is monotone continuous, decreasing sequence where 
$$\lim_{n \rightarrow \infty} \frac{1}{n} = \lim_{n \rightarrow \infty}  n^{-1} = 0$$

This gives us a limit to the sequence of $A_n$,  
$$\lim_{n \rightarrow \infty} A_n = \bigcap\limits_{i=1}^{\infty}A_i  = \lim_{n \rightarrow \infty} \{ X \leq x + n^{-1}\} = \lim_{n \rightarrow \infty} \{ X \leq x + 0\} = \{ X \leq x \}$$

Evaluating the associated probabilities gives us: 

$$\lim_{n \rightarrow \infty}{P(A_n)} = P(\bigcap\limits_{i=1}^{\infty}A_i) = P(\{ X \leq x \})  = F(x)$$

$$F(x) = \lim_{n \rightarrow \infty} P(\{ X \leq x + n^{-1}\}) = \lim_{n \rightarrow \infty} F(x + n^{-1})$$

Such that: 
$$lim_{n \rightarrow \infty} {F(x + n^{-1})} = F(x)$$

And conclude: right continuity, $F(x_n) \downarrow F(x)$
