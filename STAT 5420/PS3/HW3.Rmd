---
title: "HW3"
output: pdf_document
date: "2024-09-28"
---
# HW 3
[Name: Sam Olson]{.smallcaps} \
[Collaborators: **Tne Hatman**]{.smallcaps} \

# Overview 
  - 1: Fix up f(y) calculation
  - 2: Part (b), (c) left TO-DO
  - 3: Part (c) left TO-DO
  - 4: DONE
  - 5: 
  - 6: JANKY
  - 7: 
  - 8: 

> 1. 2.23(b) 

## Question 1
Let X have the pdf

$$f(x) = \frac{1}{2}(1+x)$$, $-1<x<1$

Define the random variable Y by $Y = X^2$

(b): Find $E(Y)$ and Var(Y). 

## Answer 1  

```{r}
x <- seq(from = -1, to = 1, by = 0.01)
y <- 1/2 * (1+x)
plot(x, y)
```

(b): 

(From prior HW) Note from the results of theorem 2.1.8: 

$$f_Y(y) =
\begin{cases}
  \sum \limits_{i=1}^{k} f_X(g^{-1}_i(y))|\frac{d}{dy}g_{i}^{-1}(y)| & y \in \mathbb{Y} \\
  0 & otherwise \\ 
\end{cases}$$

Over the following partitions, we have monotonicity, 

$A_1 = (-1, 0)$, 
$A_2 = (0, 1)$, with 

$g_1(x) = x^2$ on their respective intervals.

Giving 

$f_Y(y) = \frac{1}{2\sqrt y}$, $0 < y < 1$

Calculations: 

$E(Y) = \int\limits_{y \in \mathbb{Y}} yf(y)dy = \int\limits_{y=0}^{1} y(\frac{1}{2\sqrt y})dy$

$$E(Y) = \int\limits_{y=0}^{1} \sqrt y (\frac{1}{2})dy = \frac{1}{2} \frac{2}{3} y^{3/2} \big|_{y=0}^{y=1} = \frac{1}{2} \frac{2}{3} (1) - 0 = \frac{1}{3}$$

To calculate Var(Y), let us consider $E(Y^2)$, 

$E(Y^2) = \int\limits_{y \in \mathbb{Y}} y^2f(y)dy = \int\limits_{y=0}^{1} y^2(\frac{1}{2\sqrt y})dy$

$$E(Y^2) = \int\limits_{y=0}^{1} y^{3/2} \frac{1}{2} dy = \frac{2}{5} (\frac{1}{2}) y^{5/2} \big|_{y=1}^{y=1} = \frac{2}{5} (\frac{1}{2}) (1) - 0 = \frac{2}{10} = \frac{1}{5}$$
Taking Var(Y) = $E(Y^2) - (E(Y))^2$, then, 

$Var(Y) = \frac{1}{5} - (\frac{1}{3})^2 = \frac{1}{5} - \frac{1}{9} = \frac{9}{45} - \frac{5}{45} = \frac{4}{45}$

\newpage

> 2. 

## Question 2
A family continues to have children until they have one female child. Suppose, for each birth, a single child is born and the child is equally likely to be male or female. The gender outcomes are independent across births. 

(a): Let X be a random variable representing the number of children born to this family. Find the distribution of X. 

(b): Find the expected value $E(X)$

(c): Let $X_m$ denote the number of male children in this family and let $X_f$ denote the number of female children. Find the expected value of $X_m$ and the expected value of $X_f$

## Answer 2

(a): We can frame X as the number of children until the family has their first (one) female child. So we can think of X as a Geometric distribution with probability $p=0.5$ since it is equally likely that they have a male/female for each birth. 

Notation-wise we write this as: 

$X \sim \text{Geometric}(p = 0.5)$

(b): 

Knowing the distribution of X, we know its pmf (discrete!) is given by: 

For X number of children, $k=1, 2, ...$, we have: 

$f_X(x) = P(X = x) = p(1-p)^{x-1}$

$$E(X) = \sum\limits_{x=1}^{\infty} x P(X = x) = \sum\limits_{k=x}^{\infty} x (p(1-p)^{x-1}) = p \sum\limits_{x=1}^{\infty} x ((1-p)^{k-1})$$

Note, for the infinite geometric series we have, for $|r| < 1$, k some positive integer, the following holds: 
$$\sum\limits_{k = 1}^{\infty} r^{k-1} = \frac{1}{1-r}$$

Note: as $0 < p < 1 \rightarrow 0 < 1-p < 1$, giving us: 

$$E(X) = p \sum\limits_{k=1}^{\infty} k ((1-p)^{k-1})$$


$$E(X) = \frac{1}{p} = \frac{1}{0.5} = 2$$

(c): 

\newpage

> 3. 2.30 (a), (b), (c)

## Question 3
Find the moment generating function corresponding to: 

(a): $f(x) = \frac{1}{c}$, $0<x<c$

(b): $f(x) = \frac{2x}{c^2}$, $0<x<c$

(c): $f(x) = \frac{1}{2\beta}e^{\frac{-|x-\alpha|}{\beta}}$, $-\infty < x < \infty$, $-\infty < \alpha < \infty$, $\beta > 0$

## Answer 3

Note, for a continuous random variable X, we may write the moment generating funciton as: 

$$M_X(t) = \int\limits_{-\infty}^{\infty}{e^{tx} f_X(x) dx}$$

Using this method, we then calculate the following:

(a):

$$M_X(t) = \int\limits_{-\infty}^{\infty}{e^{tx} f_X(x) dx} = \int\limits_{0}^{c}{e^{tx} \frac{1}{c} dx} = \frac{1}{ct}e^{tx} \big|_{x=0}^{x=c} = \frac{1}{ct}e^{tc} - \frac{1}{ct}(1)$$

$$M_X(t) = \frac{1}{ct}e^{tc} - \frac{1}{ct}(1) = \frac{1}{ct}(e^{tc} -1)$$

(b): 

$$M_X(t) = \int\limits_{-\infty}^{\infty}{e^{tx} f_X(x) dx} = \int\limits_{0}^{c}{e^{tx}} \frac{2x}{c^2} dx = \frac{2}{c^2t^2}e^{tx}(tx-1) \big|_{x=0}^{x=c}$$

$$M_X(t) = \frac{2}{c^2t^2}e^{tc}(tc-1) - (\frac{2}{c^2t^2}1(-1)) = \frac{2}{c^2t^2}(tce^{tc} - e^{tc} + 1)$$

(c): 

\newpage

> 4. 2.31

## Question 4
Does a distribution exist for which $M_X(t) = \frac{t}{(1-t)}$, $|t| < 1$? If yes, find it. If no, prove it. 

## Answer 4

Let us suppose that the distribution exists. 

Then by the definition of a(n) mfg: 

$M_X(t) = E(e^{tX})$

We know for $t=0$ that the relation $|t| = | 0 | = 0 < 1$ holds. 

Thus we know the 0-th moment is defined, as: 

$M_X(0) = E(e^{0X}) = E(e^0) = E(1) = 1$

However, if we evaluate $M_X(t)$ directly using the mgf as given, for $t=0$ as given, we have: 

$M_X(t) = \frac{t}{(1-t)} = \frac{0}{1-0} = 0$

And we arrive at a contradiction. Thus we must conclude that such a distribution does not exist. 

\newpage

> 5. 

## Question 5
Suppose that X has the standard normal distribution with pdf: 

$$f(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}$$, $-\infty < x < \infty$

Then the random variable Y, $Y=e^{X}$ has a log-normal distribution. 

(a): Find $E(Y^r)$ for any r. 

(b): Show the moment generating function of Y does not exist (even though all moments of Y exist). 

## Answer 5

(a):

(b): 

\newpage

> 6. 

## Question 6 
Suppose that X has a normal distribution with pdf: 

$$f(x) \frac{1}{\sigma\sqrt{2\pi}} e^{\frac{-(x-\mu)^2}{\sigma^22}}$$, $-\infty < x < \infty$

The mean of X is $\mu$. Show that the moment generating function of X satisfies $M_X(t) \geq e^{t\mu}$

## Answer 6

With note of Jensen's Inequality, we have, for a concave function, 

$$E[f(X)] \leq f(E(X))$$

We know $E(X) = \mu$, such that

$$E[f(x)] \leq f(\mu)$$
Let us then consider the mgf of $X$, $M_X(t)$. Given the above, $f(x)'' < 0$ (always negative second derivative), such that we are assured of concavity. 

Then we may directly make use of Jensen's inequality to conclude: 

$f(\mu) = e^{t\mu} \leq M_X(t)$

$M_X(t) = E[e^{tX}]$

Given concavity we know: 
$$E(g(X)) \leq g(E(X))$$


\newpage

> 7. 

## Question 7
Suppose that $X$ has pmf $f(x) = p(1-p)^{x-1}$, for $x = 1, 2, 3, ...$ where $0<p<1$. Find the mgf $M_X(t)$ and use this to derive the mean and variance of X. 

## Answer 7



\newpage

> 8.

## Question 8
Suppose for one month a company purfchases c copies of a software package at a cost of $d_1$ dollars per copy. The packages are sold to customers for $d_2$ dollars per copy; any unsold copies are destroyed at the end of the month. Let $X$ represent the demand for this software package in the month. Assume that $X$ is a discrete random variable with pmf $f(x)$ and cdf $F(x)$. 

(a): Let $s = \text{min} \{ X, c\}$ represent the number of sales during the month. Show that:

$$E(S) = \sum\limits_{x=0}^{c} xf(x) + c(1-F(c))$$

(b): Let $Y = S * d_2 - cd_1$ represent the profit for the company, the total income from sales minus the total cost of all copies. Find $E(Y)$

(c): As $Y \equiv Y_c$ depends on integer $c \geq 0$, write the expected profit function as $g(c) \equiv E(Y_c)$ from part (b). The company should choose the value of c which maximizes $g(c)$; that is, choose the smallest c such that $g(c+1)$ is less than or equal to $g(c)$. Show that such $c \geq 0$ is the smallest integer with $F(c) \geq \frac{d_2 - d_1}{d_2}$

## Answer 8

(a): 

(b): 

(c): 
